# Unmapped RNA-seq rumen epimural community
---
*5/3/2018*

These are my notes on the separation of unmapped reads from Wenli's rumen epimural sequencing project.

## Table of Contents


## Generating unmapped read fastqs

Here is the location of the unmapped read bam files generated by TopHat:

> /mnt/nfs/nfs2/bickhart-users/cattle_asms/Rumen_epimural_RNAseq

Let's index them and check them for unmapped segments.

> Assembler2: /mnt/nfs/nfs2/bickhart-users/cattle_asms/Rumen_epimural_RNAseq

```bash
module load samtools; for i in *.bam; do echo $i; samtools index $i; done


```

## Running trinity assembly of Rna seq transcripts

> Ceres:

```bash
# Generating list of different rumens and technical replicate files
ls *.fastq.gz > trinity_rna_replicates.tab

module load bedtools samtools salmon trinityrnaseq/2.6.6

sbatch --nodes=1 --mem=75000 --ntasks-per-node=10 -p medium --wrap="Trinity --seqType fq --max_memory 75G --CPU 10 --trimmomatic --output trinity_epimural_assembly --samples_file trinity_rna_replicates.tab"

# Damn! The quality control step failed, so I need to reprocess the reads.
# The program is too stringent with read-name quality filtering, so I need to reprocess all of the reads
for i in *_R1.fastq.gz; do echo $i; name=`echo $i | cut -c1-9`; echo $name; sbatch -p short process_read_name.pl $i 1 $name"_format_R1.fastq"; done
for i in *_R2.fastq.gz; do echo $i; name=`echo $i | cut -c1-9`; echo $name; sbatch -p short process_read_name.pl $i 2 $name"_format_R2.fastq"; done

perl -lane '$F[2] = substr($F[2], 0, 9) . "_format_R1.fastq.gz"; $F[3] = substr($F[3], 0, 9) . "_format_R2.fastq.gz"; print join("\t", @F);' < trinity_rna_replicates.tab > trinity_rna_replicates.reformat.tab

sbatch --nodes=1 --mem=75000 --ntasks-per-node=10 -p medium --wrap="Trinity --seqType fq --max_memory 75G --CPU 10 --trimmomatic --output trinity_epimural_rerun --samples_file trinity_rna_replicates.reformat.tab"

# That ran out of memory! It's because I have around 150 million read pairs and I need 1 gig per read pair
sbatch --nodes=1 --mem=151000 --ntasks-per-node=15 -p mem --wrap="Trinity --seqType fq --max_memory 150G --CPU 15 --trimmomatic --output trinity_epimural_highmem --samples_file trinity_rna_replicates.reformat.tab"

# Damn, even that ran out of memory!
module load bedtools samtools salmon trinityrnaseq/2.6.6; sbatch --nodes=1 --mem=300000 --ntasks-per-node=15 -p mem --wrap="Trinity --seqType fq --max_memory 300G --CPU 15 --trimmomatic --output trinity_epimural_highermem --samples_file trinity_rna_replicates.reformat.tab"

# OK, this is the last try. This is pretty ridiculous
module load bedtools samtools salmon trinityrnaseq/2.6.6; sbatch --nodes=1 --mem=500000 --ntasks-per-node=20 -p mem --wrap="Trinity --seqType fq --max_memory 500G --CPU 20 --trimmomatic --output trinity_epimural_highestmem --samples_file trinity_rna_replicates.reformat.tab"
```