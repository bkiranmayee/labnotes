# Cattle genome assembly and validation
---
*10/26/2016*

## Table of Contents
* [Sequence alignment and summary statistics](#stats)
* [Polished assembly](#polish)
* [Recombination map alignment and problem region identification](#recomb)
* [SNP remapping and stats](#snps)

<a name="stats"></a>
## Sequence alignment and summary statistics

I need to align the data to the following cattle assemblies: 

* The UMD3 assembly
* The Btau4 assembly
* The PacBio contigs (the march Cattle assembly)
* The finished assembly (to be generated by Aleksey)

Let's start aligning to the assemblies I have right now. I'm also going to generate the spreadsheet with the information.

> Blade14: /mnt/nfs/nfs2/dbickhart/dominette_asm

```bash
ls /mnt/nfs/nfs2/SequenceData/Dominette/Dominette_NextSeq_data/*/*.fastq.gz | perl -MFile::Basename -e '%data; while(<>){chomp; $orig = $_; $bname = basename($_); @entries = split(/\//, $orig); @bentries = split(/_/, $bname); $data{"$entries[-2]_$bentries[2]"}->{$bentries[3]} = $orig;} foreach my $k (keys(%data)){print $data{$k}->{"R1"} . "\t" . $data{$k}->{"R2"} . "\tdominette\tdominette\n";}' > dominette_nextseq_file_list.tab

# UMD3
perl ~/perl_toolchain/sequence_data_pipeline/runMergedBamPipeline.pl --fastqs dominette_nextseq_file_list.tab --output umd3 --reference ../../Genomes/Bos_taurus.UMD3.1.73.fa --config ./quick_pipeline.cnfg --threads 4

```

Serge's pipeline only works with SGE. I need to hijack some of his commands to run Lumpy and the other tools without using his full pipeline.

```bash
# Preparing discordant and split read bam files
samtools view -b -F 1294 btau4/dominette_merged_btau4.bam > btau4/dominette_merged_btau4.discordants.bam
samtools view -h btau4/dominette_merged_btau4.bam \
          | ~/lumpy-sv/scripts/extractSplitReads_BwaMem -i stdin \
          | samtools view -Sb - \
          > btau4/dominette_merged_btau4.splitters.bam

samtools index btau4/dominette_merged_btau4.discordants.bam
samtools index btau4/dominette_merged_btau4.splitters.bam

# Lumpy analysis
pars=`samtools view btau4/dominette_merged_btau4.bam | head -n100000 | ~/lumpy-sv/scripts/pairend_distro.py -r 150 -X 4 -N 10000 -o btau4/dominette_merged_btau4.histo`
mean=`echo $pars | grep 'mean' | awk '{print $1}' |sed s/mean://g`
sd=`echo $pars |grep 'mean' | awk '{print $NF}' |sed s/stdev://g`
MIN=`echo "$mean $sd" |awk '{printf("%d\n", $1-3*$2)}' |awk '{if ($1 < 0) print 0}'`
MAX=`echo "$mean $sd" |awk '{printf("%d\n", $1+3*$2)}'`

PE=""
SR=""

PE="$PE -pe id:sample,bam_file:btau4/dominette_merged_btau4.discordants.bam,histo_file:btau4/dominette_merged_btau4.histo,mean:$mean,stdev:$sd,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20"
SR="$SR -sr id:sample,bam_file:btau4/dominette_merged_btau4.splitters.bam,back_distance:10,min_mapping_threshold:20,weight:1,min_clip:20"
lumpy -mw 4 -tt 0 $PE $SR > btau4/dominette_merged_btau4.lumpy.vcf

# FRC bam
PE=""
PE="$PE --pe-sam btau4/dominette_merged_btau4.bam --pe-max-insert $MAX"
FRC $PE --genome-size $GS --output btau4/dominette_merged_btau4

# Freebayes
$FREEBAYES -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 1 -F 0.5 -b btau4/dominette_merged_btau4.bam -v btau4/dominette_merged_btau4.bayes.vcf -f $ASM

# QV estimate
NUM_SNP=`cat btau4/dominette_merged_btau4.bayes.vcf |grep -v "#" | awk -F "\t" '{print $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$8}' | tr ';' ' ' | sed s/AB=//g | awk -v WEIGHT=$WEIGHT '{if ($6 > WEIGHT) print $0}' | awk -v SUM=0 '{if (length($4) == length($5)) { SUM+=length($4); } else if (length($4) < length($5)) { SUM+=length($5)-length($4); } else { SUM+=length($4)-length($5)}} END { print SUM}'`

NUM_BP=`samtools depth btau4/dominette_merged_btau4.bam |awk '{if ($NF >= 3) SUM++; } END { print SUM}'`
QV=`echo "$NUM_SNP $NUM_BP" | awk '{print (-10*log($1/$2)/log(10))}'`
echo $QV > btau4/dominette_merged_btau4.qv
```

I consolidated the above code into a shell script that can run on each merged bam file in sequence.

```bash
sh serge_script_oneshot.sh btau4/dominette_merged_btau4 /mnt/iscsi/vnx_gliu_7/reference/bosTau4.fa.gz

sh serge_script_oneshot.sh umd3/dominette.merged.umd3 /mnt/iscsi/vnx_gliu_7/reference/umd3_kary_unmask_ngap.fa

sh serge_script_oneshot.sh canu/canu.dominette.topolish canu/topolish.filledWithCanuAndPBJelly.fasta
```

I am also queuing up the new assembly (pre pilon).

```bash
bwa index canu/topolish.filledWithCanuAndPBJelly.fasta.gz ; samtools faidx canu/topolish.filledWithCanuAndPBJelly.fasta.gz ; perl ~/perl_toolchain/sequence_data_pipeline/runMergedBamPipeline.pl --fastqs dominette_nextseq_file_list.tab --output canu --reference canu/topolish.filledWithCanuAndPBJelly.fasta.gz --config ./quick_pipeline.cnfg --threads 4
```

OK, the shell script had a few problems. For starters, freebayes can't handle gzipped fastas. Rerunning the last steps of the pipeline.

```bash
# btau4
samtools depth dominette_merged_btau4.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
	2697640645
freebayes -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 2 -F 0.5 -b dominette_merged_btau4.bam -v dominette_merged_btau4.bayes.vcf -f /mnt/iscsi/vnx_gliu_7/reference/bosTau4.fa
perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < dominette_merged_btau4.bayes.vcf
	281999

perl -e '$ns = 281999; $nb = 2697640645; print (-10 * log($ns/$nb)/log(10)); print "\n";'
	39.8073652818702 # Btau4 qv

perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f dominette_merged_btau4_Features.txt -c 1
Entry   Count
COMPR_PE        6407
HIGH_COV_PE     4406
HIGH_NORM_COV_PE        3671
HIGH_OUTIE_PE   988
HIGH_SINGLE_PE  3247
HIGH_SPAN_PE    9240
LOW_COV_PE      135529
LOW_NORM_COV_PE 137377
STRECH_PE       16385

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < dominette_merged_btau4.lumpy.vcf | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        12870
DUPLICATION     1305
INTERCHROM      9031
INVERSION       2152

# Errors per 100 mbp = (25358 / 28.0) = 905.64

# umd3
samtools depth dominette.merged.umd3.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
	2633997017
freebayes -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 2 -F 0.5 -b dominette.merged.umd3.bam -v dominette.merged.umd3.bayes.vcf -f ../../../Genomes/Bos_taurus.UMD3.1.73.fa
perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < dominette.merged.umd3.bayes.vcf
	300091

perl -e '$ns = 300091; $nb = 2633997017; print (-10 * log($ns/$nb)/log(10)); print "\n";'
	39.4336230805122 # UMD3 qv

perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f dominette.merged.umd3_Features.txt -c 1
Entry   Count
COMPR_PE        12348
HIGH_COV_PE     7660
HIGH_NORM_COV_PE        7169
HIGH_OUTIE_PE   2303
HIGH_SINGLE_PE  1295
HIGH_SPAN_PE    4135
LOW_COV_PE      64527
LOW_NORM_COV_PE 67417
STRECH_PE       21891

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < dominette.merged.umd3.lumpy.vcf | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        13963
DUPLICATION     2493
INTERCHROM      8711
INVERSION       5470

# Errors per 100 mbp = (30637 / 28.0) = 1094.18


## Computomix
perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f canu/canu.dominette.topolish_Features.txt -c 1
Entry   Count
COMPR_PE        6526
HIGH_COV_PE     7333
HIGH_NORM_COV_PE        5759
HIGH_OUTIE_PE   80
HIGH_SINGLE_PE  118
HIGH_SPAN_PE    5982
LOW_COV_PE      52772
LOW_NORM_COV_PE 50719
STRECH_PE       16752

lumpy -mw 4 -tt 0 -pe id:sample,bam_file:canu.dominette.topolish.discordants.bam,histo_file:canu.dominette.topolish.histo,mean:628.478,stdev:168.47,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 -sr id:sample,bam_file:canu.dominette.topolish.splitters.bam,back_distance:10,min_mapping_threshold:20,weight:1,min_clip:20 > canu.dominette.topolish.lumpy.vcf

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < canu/canu.dominette.topolish.lumpy.vcf  | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        4272
DUPLICATION     320
INTERCHROM      2132
INVERSION       487


```

OK, let's summarize things:

| Feature | Btau4 | UMD3 | Serge | Aleksey |Description |
| :--- | ---: | ---: | ---: | ---: |:--- |
| QV | 39.80 | 39.43 | 32.78 | 38.85 | Phred-based assessment of INDEL and SNP errors in assembly |
| Errors / 100 Mbp | 905.64 | 1094.18 | 257 | 213.75 | Ratio of Lumpy SV calls per 100 Mbp |
| DELETION | 12870 | 13963 | 4272 | 1363 | Lumpy-SV deletions |
| DUPLICATION | 1305 | 2493 | 320 | 611 | Lumpy-SV duplications |
| INTERCHROM | 9031 |  8711 | 2132| 3943 | Lumpy-SV interchromosome regions |
| INVERSION | 2152 |  5470 | 487 | 68 | Lumpy-SV inversions |
|COMPR_PE         |   6407|12348| 6526| 9000 | Areas with low CE statistics |
|HIGH_COV_PE      |   4406|7660| 7333| 10098 | Higher read coverage |
|HIGH_NORM_COV_PE |   3671|7169| 5759 | 7944 | High coverage of normal paired-end reads |
|HIGH_OUTIE_PE    |    988|2303| 80| 79 | Regions with high numbers of misoriented or distant pairs |
|HIGH_SINGLE_PE   |   3247|1295| 118 | 251 |Regions with high numbers of unmapped pairs |
|HIGH_SPAN_PE     |   9240|4135| 5982 | 14180 |Regions with high numbers of disc. pairs that map to different scaffolds |
|LOW_COV_PE       | 135529|64527| 52772 | 100814 |Low read coverage |
|LOW_NORM_COV_PE  | 137377|67417| 50719 | 105271 |Low coverage of normal paired-end reads |
|STRECH_PE        |  16385|21891| 16752 | 15079 |Areas with high CE statistics |

<a name="polished"></a>
## Polished assembly

Now that we have the polished assembly back from Aleksey, it's time to process it.

```bash
module load bwa
module load samtools/1.3-20-gd49c73b

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="bwa index polished.fa"
sbatch --mem=2000 --nodes=1 --ntasks-per-node=1 --wrap="samtools faidx polished.fa"

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="java -Xmx19g -jar /mnt/nfs/nfs2/bickhart-users/binaries/GetMaskBedFasta/store/GetMaskBedFasta.jar -f polished.fa -o polished.gaps.bed -s polished.gaps.stats"
sbatch --nodes=1 --mem=2000 --ntasks-per-node=8 --wrap 'samtools merge -c -p --threads 8 polished.merged.dominette.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L001_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L002_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L003_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L004_001.bam'

sbatch --nodes=1 --ntasks-per-node=1 --mem=1000 --wrap='samtools index bwa-out/polished.merged.dominette.bam'
sbatch serge_script_oneshot.sh polished/bwa-out/polished.merged.dominette polished/polished.fa

# Lumpy failed because of weird scripting errors. Rerunning...
sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; samtools view polished.merged.dominette.bam | tail -n+100000 | /opt/agil_cluster/lumpy-sv-0.2.12-51-g16b6876/bin/../scripts/pairend_distro.py -r 150 -X 4 -N 10000 -o polished.merged.dominette.histo"

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; lumpy -mw 4 -tt 0 -pe id:dominette,bam_file:polished.merged.dominette.bam,histo_file:polished.merged.dominette.histo,mean:626.926292629,stdev:193.453829908,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 > polished.merged.dominette.lumpy.vcf"

./vcfToBedpe -i polished/bwa-out/polished.merged.dominette.lumpy.vcf -o polished/bwa-out/polished.merged.dominette.lumpy.bedpe

perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < polished.merged.dominette.bayes.vcf
353921
samtools depth polished.merged.dominette.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
2720125193
perl -e 'chomp(@ARGV); $ns = $ARGV[0]; $nb = $ARGV[1]; print (-10 * log($ns/$nb)/log(10)); print "\n";' 353921 2720125193
38.8568256039133

# Checking to see if the SNPs and indels correspond to lumpy SV calls
# Pulling lumpy calls into beds and then pulling only the >65% AB percentile variants from the freebayes output
perl -lane 'if($F[0] =~ /^#/){next;} if($F[1] < 0){ $F[1] = 0;} if($F[3] < 0){$F[3] = 0;} if($F[10] eq "BND"){print "$F[0]\t$F[1]\t$F[2]\t$F[10]"; print "$F[3]\t$F[4]\t$F[5]\t$F[10]";}else{print "$F[0]\t$F[1]\t$F[5]\t$F[10]";}' < polished.merged.dominette.lumpy.bedpe > polished.merged.dominette.lumpy.bed
perl -lane 'if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;} $e = $F[1] + 1; print "$F[0]\t$F[1]\t$e";' < polished.merged.dominette.bayes.vcf > polished.merged.dominette.bayes.bed
intersectBed -a polished.merged.dominette.lumpy.bed -b polished.merged.dominette.bayes.bed -c | perl -lane 'if($F[4] > 0){print $_;}' | wc -l
2417   <- total SNPs/INDELs within lumpy predicted discordant regions (~24% of total)
perl -lane 'if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;} $e = $F[1] + 1; print "$F[0]\t$F[1]\t$e";' < polished.merged.dominette.bayes.vcf > polished.merged.dominette.bayes.bed
[dbickhart@vm-agil-251-fry bwa-out]$ intersectBed -a polished.merged.dominette.lumpy.bed -b polished.merged.dominette.bayes.bed -c | perl -lane 'if($F[4] > 0){print $_;}' | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 3 -m
```
### Variants within lumpy sv coordinates in polished assembly
|Entry | Count|
|:-----|-----:|
|BND   |  1436|
|DEL   |   506|
|DUP   |   432|
|INV   |    43|


<a name="ctx"></a>
## Computomix assembly

The polished assembly looks corrupted... I'm going to run a comparison with the real computomix assembly to see how that panned out.

> fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/ctx

```bash
sh create_bwa_batchfiles.sh dominette_nextseq_file_list.tab
sbatch --nodes=1 --ntasks-per-node=2 --mem=10000 --wrap="module load bwa; module load samtools; bwa index CTX3.fasta; samtools faidx CTX3.fasta"

sleep 3h; find batchfiles-bwa/ -name *.sh | xargs -I {} sbatch {}
sbatch --nodes=1 --ntasks-per-node=10 --mem=5000 --wrap="module load samtools/1.3-20-gd49c73b; samtools merge -c -p -@ 9 polishedAsm.NextSeq.dominette.merged.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L001_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L002_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L003_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L004_001.bam; samtools index polishedAsm.NextSeq.dominette.merged.bam;"

sbatch ../serge_script_oneshot.sh bwa-out/polishedAsm.NextSeq.dominette.merged CTX3.fasta dominette
```

## Other assemblies

Aleksey made two additional assemblies that need to be run through the pipeline.

> fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/

```bash
#### Polished.final ####
mkdir polished.final
cd polished.final

sbatch --nodes=1 --mem=6000 --ntasks-per-node=1 --wrap="module load bwa; module load samtools; wget ftp://ftp.genome.umd.edu/pub/dominette/polished.final.fa.gz; gunzip polished.final.fa.gz; bwa index polished.final.fa; samtools faidx polished.final.fa;"

perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b alignments -t ../dominette_nextseq_file_list.tab -f polished.final.fa -m
sbatch serge_script_oneshot.sh polished.final/alignments/dominette/dominette.sorted.merged polished.final/polished.final.fa dominette

#### Topolish no 1b ####
mkdir topolish.no1b
cd topolish.no1b

sbatch --nodes=1 --mem=6000 --ntasks-per-node=1 --wrap="module load bwa; module load samtools; wget ftp://ftp.genome.umd.edu/pub/dominette/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta.gz; gunzip topolish.filledWithCanuAndPBJelly.withX.no1b.fasta.gz; bwa index topolish.filledWithCanuAndPBJelly.withX.no1b.fasta; samtools faidx topolish.filledWithCanuAndPBJelly.withX.no1b.fasta;"

perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b alignments -t ../dominette_nextseq_file_list.tab -f topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -m
sbatch serge_script_oneshot.sh topolish.no1b/alignments/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta dominette

# Damn, I suspect that Slurm automatically kills jobs that post with an ampersand. Going to queue up FRC and lumpy using separate commands
sbatch --nodes=1 --ntasks-per-node=2 --mem=25000 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; lumpy -mw 4 -tt 0  -pe id:dominette,bam_file:topolish.no1b/alignments/dominette/dominette.sorted.merged.discordants.bam,histo_file:topolish.no1b/alignments/dominette/dominette.sorted.merged.histo,mean:626.861177885,stdev:184.997331276,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 > topolish.no1b/alignments/dominette/dominette.sorted.merged.lumpy.2.vcf"
sbatch --nodes=1 --ntasks-per-node=2 --mem=25000 --wrap="module load FRC_align/1.3.0-5b3f53e; FRC  --pe-sam topolish.no1b/alignments/dominette/dominette.sorted.merged.bam --pe-max-insert 1181 --genome-size 2800000000 --output topolish.no1b/alignments/dominette/dominette.sorted.merged.2"

sbatch --nodes=1 --ntasks-per-node=2 --mem=25000 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; lumpy -mw 4 -tt 0  -pe id:dominette,bam_file:polished.final/alignments/dominette/dominette.sorted.merged.discordants.bam,histo_file:polished.final/alignments/dominette/dominette.sorted.merged.histo,mean:666.1878,stdev:182.802370146,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 > polished.final/alignments/dominette/dominette.sorted.merged.lumpy.2.vcf"
```

#### Update of stats table

| Feature | Btau4 | UMD3 | Serge | Aleksey | polished.final | topolish.no1b |Description |
| :--- | ---: | ---: | ---: | ---: | ---: | ---: |:--- |
| QV | 39.80 | 39.43 | 32.78 | 38.85 | 38.23 | 40.87 |Phred-based assessment of INDEL and SNP errors in assembly |
| Errors / 100 Mbp | 905.64 | 1094.18 | 257 | 213.75 | | | Ratio of Lumpy SV calls per 100 Mbp |
| DELETION | 12870 | 13963 | 4272 | 1363 | | | Lumpy-SV deletions |
| DUPLICATION | 1305 | 2493 | 320 | 611 | | | Lumpy-SV duplications |
| INTERCHROM | 9031 |  8711 | 2132| 3943 | | | Lumpy-SV interchromosome regions |
| INVERSION | 2152 |  5470 | 487 | 68 | | | Lumpy-SV inversions |
|COMPR_PE         |   6407|12348| 6526| 9000 | 68847 | 174622 | Areas with low CE statistics |
|HIGH_COV_PE      |   4406|7660| 7333| 10098 | 10320 | 7214 | Higher read coverage |
|HIGH_NORM_COV_PE |   3671|7169| 5759 | 7944 | 8185 | 5481 | High coverage of normal paired-end reads |
|HIGH_OUTIE_PE    |    988|2303| 80| 79 | 133 | 122 | Regions with high numbers of misoriented or distant pairs |
|HIGH_SINGLE_PE   |   3247|1295| 118 | 251 | 306 | 92 | Regions with high numbers of unmapped pairs |
|HIGH_SPAN_PE     |   9240|4135| 5982 | 14180 | 14993 | 5166 | Regions with high numbers of disc. pairs that map to different scaffolds |
|LOW_COV_PE       | 135529|64527| 52772 | 100814 | 107927 | 58672 | Low read coverage |
|LOW_NORM_COV_PE  | 137377|67417| 50719 | 105271 | 111927 | 57701 | Low coverage of normal paired-end reads |
|STRECH_PE        |  16385|21891| 16752 | 15079 | 39885 | 94925 | Areas with high CE statistics |


Now to generate a FRC curve to compare stats.

```R
data.serge <- read.delim("canu/canu.dominette.topolish_FRC.txt", sep=" ", header=FALSE)
data.aleksey <- read.delim("polished/bwa-out/polished.merged.dominette_FRC.txt", sep=" ", header=FALSE)
data.topolish <- read.delim("topolish.no1b/alignments/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.final <- read.delim("polished.final/alignments/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
pdf(file="frc_curve_fourasms.pdf", useDingbats=FALSE)

plot(data.serge$V1, data.serge$V2, type="l", col="red")
lines(data.aleksey$V1, data.aleksey$V2, col="green")
lines(data.topolish$V1, data.topolish$V2, col="blue")
lines(data.final$V1, data.final$V2, col="brown")
legend("topleft", legend = c("Serge", "Aleksey1", "Aleksey2", "topolishNob1"), col = c("red", "green", "blue", "brown"))
dev.off()

pdf(file="frc_curve_threeasms.pdf", useDingbats=FALSE)
plot(data.aleksey$V1, data.aleksey$V2, col="green", type="l")
lines(data.topolish$V1, data.topolish$V2, col="blue")
lines(data.final$V1, data.final$V2, col="brown")
legend("topleft", legend = c("Aleksey1", "Aleksey2", "topolishNoB1"), lty=c(1,1), lwd=c(2,2), col = c("green", "blue", "brown"))

```

Rerunning only on run2 data

```bash
mkdir run2only
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b umd3 -t ../dominett_run2_only_files.tab -f /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b canu -t ../dominett_run2_only_files.tab -f ../canu/topolish.filledWithCanuAndPBJelly.fasta -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b ctx -t ../dominett_run2_only_files.tab -f ../ctx/CTX3.fasta -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b polished -t ../dominett_run2_only_files.tab -f ../polished/polished.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b polished.final -t ../dominett_run2_only_files.tab -f ../polished.final/polished.final.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b topolish.no1b -t ../dominett_run2_only_files.tab -f ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -m

sbatch serge_script_oneshot.sh run2only/canu/dominette/dominette.sorted.merged canu/topolish.filledWithCanuAndPBJelly.fasta dominette
sbatch serge_script_oneshot.sh run2only/ctx/dominette/dominette.sorted.merged ctx/CTX3.fasta dominette
sbatch serge_script_oneshot.sh run2only/umd3/dominette/dominette.sorted.merged /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa dominette
sbatch serge_script_oneshot.sh run2only/polished/dominette/dominette.sorted.merged polished/polished.fa dominette
sbatch serge_script_oneshot.sh run2only/polished.final/dominette/dominette.sorted.merged polished.final/polished.final.fa dominette
sbatch serge_script_oneshot.sh run2only/topolish.no1b/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta dominette
```

Rerunning only on run1 data

```bash
mkdir run1only
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b umd3 -t ../dominette_run1_only_nextseq_file_list.tab -f /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b canu -t ../dominette_run1_only_nextseq_file_list.tab -f ../canu/topolish.filledWithCanuAndPBJelly.fasta -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b ctx -t ../dominette_run1_only_nextseq_file_list.tab -f ../ctx/CTX3.fasta -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b polished -t ../dominette_run1_only_nextseq_file_list.tab -f ../polished/polished.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b polished.final -t ../dominette_run1_only_nextseq_file_list.tab -f ../polished.final/polished.final.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b topolish.no1b -t ../dominette_run1_only_nextseq_file_list.tab -f ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -m

# Running all of the diagnostic scripts as dependent jobs
sbatch --dependency=afterok:656252 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/topolish.no1b/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta dominette
sbatch --dependency=afterok:656247 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/polished.final/dominette/dominette.sorted.merged polished.final/polished.final.fa dominette
sbatch --dependency=afterok:656242 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/polished/dominette/dominette.sorted.merged polished/polished.fa dominette
sbatch --dependency=afterok:656237 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/ctx/dominette/dominette.sorted.merged ctx/CTX3.fasta dominette
sbatch --dependency=afterok:656232 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/canu/dominette/dominette.sorted.merged canu/topolish.filledWithCanuAndPBJelly.fasta dominette
sbatch --dependency=afterok:656227 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/umd3/dominette/dominette.sorted.merged /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa dominette

for i in `ls run1only/*/dominette/dominette.sorted.merged.lumpy.vcf`; do dir=`dirname $i`; echo $dir; ./vcfToBedpe -i $i -o $dir/dominette.sorted.merged.lumpy.bedpe; done
perl ../../bickhart-users/binaries/GoatAssemblyScripts/assembly_frc_benchmarking/summarizeAnalysisSlurm.pl -b run1only/canu/dominette/dominette.sorted.merged,run1only/ctx/dominette/dominette.sorted.merged,run1only/polished/dominette/dominette.sorted.merged,run1only/polished.final/dominette/dominette.sorted.merged,run1only/topolish.no1b/dominette/dominette.sorted.merged,run1only/umd3/dominette/dominette.sorted.merged -n canu,ctx,polished,polished.final,topolish.no1b,umd3 -o slurm_summary_stats_run2only.md
```

|Entry            | canu | ctx |polished|p.final|topolish.no1b| umd3|
|:----------------|-----:|-----:|-----:|-----:|-----:|-----:|
|BND              |  3157|   842|  4077|  3298|  2681| 13258|
|INV              |    85|    83|   110|    99|    73|  2157|
|DEL              |  1593|  1348|  2159|  2013|  1491| 12069|
|DUP              |   450|   458|  1120|  1202|   439|  3222|
|HIGH_COV_PE      |  7419|  7498|  9743|  9844|  7234|  6605|
|HIGH_NORM_COV_PE |  5567|  5573|  7581|  7656|  5464|  5849|
|HIGH_OUTIE_PE    |    85|    41|    80|    95|    90|  2280|
|HIGH_SINGLE_PE   |   191|   242|   234|   253|    83|  1289|
|HIGH_SPAN_PE     |  9926|  9480| 13695| 13784|  4986|  3959|
|LOW_COV_PE       | 42779| 36226| 75878| 76200| 55912| 50934|
|LOW_NORM_COV_PE  | 41385| 34820| 82166| 82693| 55203| 55638|
|STRECH_PE        | 27257| 25495| 26656| 25697| 27470| 28936|
|COMPR_PE         | 13937| 17704| 28604| 24878| 14454| 22221|
|QV               |    41|    41|    40|    40|    41|    41|


Plotting the data in an FRC curve in R

```R
data.canu <- read.delim("run1only/canu/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.ctx <- read.delim("run1only/ctx/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.polished <- read.delim("run1only/polished/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.polished.final <- read.delim("run1only/polished.final/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.topolish.no1b <- read.delim("run1only/topolish.no1b/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.umd3 <- read.delim("run1only/umd3/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)

pdf(file="frc_curve_run1only_data_frc.pdf", useDingbats=FALSE)

plot(data.canu$V1, data.canu$V2, type="l", col="red")
lines(data.ctx$V1, data.ctx$V2, col="blue")
lines(data.polished$V1, data.polished$V2, col="green")
lines(data.polished.final$V1, data.polished.final$V2, col="brown")
lines(data.topolish.no1b$V1, data.topolish.no1b$V2, col="purple")
lines(data.umd3$V1, data.umd3$V2, col="orange")
legend("topleft", legend = c("canu", "ctx", "polished", "polished.final", "topolish.no1b", "umd3"), lty=c(1,1), lwd=c(2,2), col=c("red", "blue", "green", "brown", "purple", "orange"))

dev.off()
```

OK our decision was to go with the topolish.no1b assembly.

<a name="recomb"></a>
## Recombination map alignment and problem region identification 

Using the recombination map information, I need to remap probes and identify breakpoints in order. Bob has data on his comparisons with the linkage map he has in his database. Both the recombination map and linkage map are highly similar, so they are all but interchangeable. I am going to remap probes and identify the major breakpoints.

First things first, let's extract the fasta sequence from the manifest file.

> Fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/recombination

```bash
perl -e 'for(my $x = 0; $x < 8; $x++){<>;} while(<>){chomp; @s = split(/,/); print ">$s[1].$s[9].$s[10]\n$s[5]\n";}' < rcmap_manifest.csv > rcmap_manifest.fa

sbatch alignAndOrderSnpProbes.pl -a ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -p rcmap_manifest.fa -o rcmap_test_run_topolish.no1b

# Testing canu alignments on topolish:
perl alignAndOrderSnpProbes.pl -n toPolishVsCanu.long1coords -o toPolishVsCanuTest

# Identifying regions that have zero read coverage in topolish
sbatch --nodes=1 --mem=20000 --ntasks-per-node=1 --wrap="module load bedtools/2.25.0; bedtools genomecov -ibam topolish.no1b/alignments/dominette/dominette.sorted.merged.bam -g topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -d | perl -lane 'if($F[2] == 0){print $_;}' > topolish.no1b/topolish.no1b.bases_zero_cov.tab"

perl condense_zero_cov_regions.pl topolish.no1b.cov.tab topolish.no1b.bases_zero_cov.bed

sbatch --nodes=1 --mem=10000 --ntasks-per-node=2 --wrap="module load java/jdk1.8.0_92; java -Xmx10g -jar ../../../bickhart-users/binaries/GetMaskBedFasta/store/GetMaskBedFasta.jar -f topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -o topolish.filledWithCanuAndPBJelly.withX.no1b.gaps.bed -s topolish.filledWithCanuAndPBJelly.withX.no1b.gaps.stats"

# Removing zero coverage bases under 5bp (most indels
perl -lane 'if($F[2] - $F[1] > 5){print $_;}' < topolish.no1b.bases_zero_cov.bed > topolish.no1b.bases_zero_cov.gt5bp.bed
wc -l topolish.no1b.bases_zero_cov.bed topolish.no1b.bases_zero_cov.gt5bp.bed
  97988 topolish.no1b.bases_zero_cov.bed
  74211 topolish.no1b.bases_zero_cov.gt5bp.bed

intersectBed -a topolish.filledWithCanuAndPBJelly.withX.no1b.gaps.bed -b topolish.no1b.bases_zero_cov.gt5bp.bed -wa | wc -l
521 <- that's all 520 gaps + some bases on the side

intersectBed -a topolish.no1b.bases_zero_cov.gt5bp.bed -b topolish.filledWithCanuAndPBJelly.withX.no1b.gaps.bed -v > topolish.no1b.bases_zero_cov.gt5bp.nogaps.bed

wc -l topolish.no1b.bases_zero_cov.gt5bp.nogaps.bed
	73690 topolish.no1b.bases_zero_cov.gt5bp.nogaps.bed  <- thats 74211 zero cov - 521 gaps


```


#### condense_zero_cov_regions.pl
```perl
#!/usr/bin/perl
# A quick one-shot script designed to process a bedtools coverage bed file to identify regions of zero coverage

my $usage = "perl $0 <input bedtools coverage tab> <output zero coverage bed>\n";

chomp(@ARGV);

open(my $IN, "< $ARGV[0]") || die "$usage";
open(my $OUT, "> $ARGV[1]");
my $chr = "NA"; my $start = 0; my $end = 0; my $inzero = 0;

my $h = <$IN>;
chomp $h; my @first = split(/\t/, $h);
$chr = $first[0];
while(my $line = <$IN>){
        chomp $line;
        my @segs = split(/\t/, $line);
        if($segs[0] ne $chr){
                if($inzero){
                        print {$OUT} "$chr\t$start\t$end\n";
                        $inzero = 0;
                        $start = 0; $end = 0;
                }
                $chr = $segs[0];
        }elsif($inzero && $segs[2] != 0){
                print {$OUT} "$chr\t$start\t$end\n";
                $inzero = 0;
                $start = 0; $end = 0;
        }elsif($segs[2] == 0 && !$inzero){
                $inzero = 1;
                $start = $segs[1];
                $end = $segs[1];
        }elsif($inzero){
                $end = $segs[1];
        }
}
close $IN;

if($inzero){
        print {$OUT} "$chr\t$start\t$end\n";
}
close $OUT;
exit;
```

<a name="longrange"></a>
## Fixing longrange issues in cattle asms

Aleksey used Bob's guides to correct the misplaced contigs on topolish.no1b. I'm going to run his assemblies through the pipeline to see how they stack up.

> /mnt/nfs/nfs2/dbickhart/dominette_asm/revised_sv_cattle_asms

```bash
sbatch --nodes=1 --mem=6000 --ntasks-per-node=1 --wrap="module load bwa; module load samtools; wget ftp://ftp.genome.umd.edu/pub/dominette/topolish.filledWithCanuAndPBJelly.withX.no1b.4rev.6rev.8fix.7rev.9fix.11fix.13rev.14rev.16fix.16rev.18rev.19rev.20fix.21fix.23fix.24rev.26fix.29rev.fasta; mv topolish.filledWithCanuAndPBJelly.withX.no1b.4rev.6rev.8fix.7rev.9fix.11fix.13rev.14rev.16fix.16rev.18rev.19rev.20fix.21fix.23fix.24rev.26fix.29rev.fasta topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa; bwa index topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa; samtools faidx topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa"

sbatch --nodes=1 --mem=1000 --ntasks-per-node=1 --dependency=afterok:656502 --wrap="perl /mnt/nfs/nfs2/bickhart-users/binaries/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b nosplit -t ../dominette_run1_only_nextseq_file_list.tab -f topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa -m"

sbatch --nodes=1 --mem=6000 --ntasks-per-node=1 --wrap="module load bwa; module load samtools; wget ftp://ftp.genome.umd.edu/pub/dominette/topolish.filledWithCanuAndPBJelly.withX.no1b.4rev.6rev.8fix.7rev.9fix.11fix.13rev.14rev.16fix.16rev.18rev.19rev.20fix.21fix.23fix.24rev.26fix.29rev.split.fasta; mv topolish.filledWithCanuAndPBJelly.withX.no1b.4rev.6rev.8fix.7rev.9fix.11fix.13rev.14rev.16fix.16rev.18rev.19rev.20fix.21fix.23fix.24rev.26fix.29rev.split.fasta topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa; bwa index topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa;  samtools faidx topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa"

sbatch --nodes=1 --mem=1000 --ntasks-per-node=1 --dependency=afterok:656504 --wrap="perl /mnt/nfs/nfs2/bickhart-users/binaries/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b split -t ../dominette_run1_only_nextseq_file_list.tab -f topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa -m"

sbatch serge_script_oneshot.sh topolish.no1b/nosplit/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa dominette
sbatch --nodes=1 --mem=15000 --ntasks-per-node=1 --wrap="module load bedtools/2.25.0; bedtools genomecov -ibam topolish.no1b/nosplit/dominette/dominette.sorted.merged.bam -bga > topolish.no1b/nosplit/dominette/dominette.sorted.merged.bedtools.cov.tab"

sbatch --dependency=afterok:656510 serge_script_oneshot.sh topolish.no1b/split/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa dominette
```

<a name="snps"></a>
## SNP remapping and stats

These are my notes on the remapping of SNP probes from the HD array to the new assembly. I have two main goals here:

* Generate a SNP location list for Paul and John to check
* Determine how many SNP locations have moved from UMD3

> 3850: /home/bickhart
```bash
perl -e 'for($x = 0; $x < 6; $x++){<>;} while(<>){chomp; if($_ =~ /^#/){next;} @s = split(/,/); @b = split(/[\[\]]/, $s[6]); $b[2] =~ tr/ACGT/TGCA/; $b[2] = reverse($b[2]); print ">$s[1].f\n$b[0]\n>$s[1].r\n$b[2]\n";} close IN;' < /work1/grw/chips/GH2/GGP_HDv2_B_StrandReport_FDT_V1.csv > ggp_probe_design.fa

perl -e 'open(O1, "> ggp_probe_design.1.fa"); open(O2, "> ggp_probe_design.2.fa"); while($n1 = <>){ $s1 = <>; $n2 = <>; $s2 = <>; $n1 =~ s/.f//; $n2 =~ s/.r//; print O1 "$n1$s1"; print O2 "$n2$s2"; }' < ggp_probe_design.fa
```

> pwd: /home/dbickhart/share/btau4_data

```bash
# I converted the BovineHD data into single line fasta entries.
```



