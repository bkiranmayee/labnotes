# Cattle genome assembly and validation
---
*10/26/2016*

## Table of Contents
* [Sequence alignment and summary statistics](#stats)
* [Polished assembly](#polish)
* [Recombination map alignment and problem region identification](#recomb)
* [SNP remapping and stats](#snps)

<a name="stats"></a>
## Sequence alignment and summary statistics

I need to align the data to the following cattle assemblies: 

* The UMD3 assembly
* The Btau4 assembly
* The PacBio contigs (the march Cattle assembly)
* The finished assembly (to be generated by Aleksey)

Let's start aligning to the assemblies I have right now. I'm also going to generate the spreadsheet with the information.

> Blade14: /mnt/nfs/nfs2/dbickhart/dominette_asm

```bash
ls /mnt/nfs/nfs2/SequenceData/Dominette/Dominette_NextSeq_data/*/*.fastq.gz | perl -MFile::Basename -e '%data; while(<>){chomp; $orig = $_; $bname = basename($_); @entries = split(/\//, $orig); @bentries = split(/_/, $bname); $data{"$entries[-2]_$bentries[2]"}->{$bentries[3]} = $orig;} foreach my $k (keys(%data)){print $data{$k}->{"R1"} . "\t" . $data{$k}->{"R2"} . "\tdominette\tdominette\n";}' > dominette_nextseq_file_list.tab

# UMD3
perl ~/perl_toolchain/sequence_data_pipeline/runMergedBamPipeline.pl --fastqs dominette_nextseq_file_list.tab --output umd3 --reference ../../Genomes/Bos_taurus.UMD3.1.73.fa --config ./quick_pipeline.cnfg --threads 4

```

Serge's pipeline only works with SGE. I need to hijack some of his commands to run Lumpy and the other tools without using his full pipeline.

```bash
# Preparing discordant and split read bam files
samtools view -b -F 1294 btau4/dominette_merged_btau4.bam > btau4/dominette_merged_btau4.discordants.bam
samtools view -h btau4/dominette_merged_btau4.bam \
          | ~/lumpy-sv/scripts/extractSplitReads_BwaMem -i stdin \
          | samtools view -Sb - \
          > btau4/dominette_merged_btau4.splitters.bam

samtools index btau4/dominette_merged_btau4.discordants.bam
samtools index btau4/dominette_merged_btau4.splitters.bam

# Lumpy analysis
pars=`samtools view btau4/dominette_merged_btau4.bam | head -n100000 | ~/lumpy-sv/scripts/pairend_distro.py -r 150 -X 4 -N 10000 -o btau4/dominette_merged_btau4.histo`
mean=`echo $pars | grep 'mean' | awk '{print $1}' |sed s/mean://g`
sd=`echo $pars |grep 'mean' | awk '{print $NF}' |sed s/stdev://g`
MIN=`echo "$mean $sd" |awk '{printf("%d\n", $1-3*$2)}' |awk '{if ($1 < 0) print 0}'`
MAX=`echo "$mean $sd" |awk '{printf("%d\n", $1+3*$2)}'`

PE=""
SR=""

PE="$PE -pe id:sample,bam_file:btau4/dominette_merged_btau4.discordants.bam,histo_file:btau4/dominette_merged_btau4.histo,mean:$mean,stdev:$sd,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20"
SR="$SR -sr id:sample,bam_file:btau4/dominette_merged_btau4.splitters.bam,back_distance:10,min_mapping_threshold:20,weight:1,min_clip:20"
lumpy -mw 4 -tt 0 $PE $SR > btau4/dominette_merged_btau4.lumpy.vcf

# FRC bam
PE=""
PE="$PE --pe-sam btau4/dominette_merged_btau4.bam --pe-max-insert $MAX"
FRC $PE --genome-size $GS --output btau4/dominette_merged_btau4

# Freebayes
$FREEBAYES -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 1 -F 0.5 -b btau4/dominette_merged_btau4.bam -v btau4/dominette_merged_btau4.bayes.vcf -f $ASM

# QV estimate
NUM_SNP=`cat btau4/dominette_merged_btau4.bayes.vcf |grep -v "#" | awk -F "\t" '{print $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$8}' | tr ';' ' ' | sed s/AB=//g | awk -v WEIGHT=$WEIGHT '{if ($6 > WEIGHT) print $0}' | awk -v SUM=0 '{if (length($4) == length($5)) { SUM+=length($4); } else if (length($4) < length($5)) { SUM+=length($5)-length($4); } else { SUM+=length($4)-length($5)}} END { print SUM}'`

NUM_BP=`samtools depth btau4/dominette_merged_btau4.bam |awk '{if ($NF >= 3) SUM++; } END { print SUM}'`
QV=`echo "$NUM_SNP $NUM_BP" | awk '{print (-10*log($1/$2)/log(10))}'`
echo $QV > btau4/dominette_merged_btau4.qv
```

I consolidated the above code into a shell script that can run on each merged bam file in sequence.

```bash
sh serge_script_oneshot.sh btau4/dominette_merged_btau4 /mnt/iscsi/vnx_gliu_7/reference/bosTau4.fa.gz

sh serge_script_oneshot.sh umd3/dominette.merged.umd3 /mnt/iscsi/vnx_gliu_7/reference/umd3_kary_unmask_ngap.fa

sh serge_script_oneshot.sh canu/canu.dominette.topolish canu/topolish.filledWithCanuAndPBJelly.fasta
```

I am also queuing up the new assembly (pre pilon).

```bash
bwa index canu/topolish.filledWithCanuAndPBJelly.fasta.gz ; samtools faidx canu/topolish.filledWithCanuAndPBJelly.fasta.gz ; perl ~/perl_toolchain/sequence_data_pipeline/runMergedBamPipeline.pl --fastqs dominette_nextseq_file_list.tab --output canu --reference canu/topolish.filledWithCanuAndPBJelly.fasta.gz --config ./quick_pipeline.cnfg --threads 4
```

OK, the shell script had a few problems. For starters, freebayes can't handle gzipped fastas. Rerunning the last steps of the pipeline.

```bash
# btau4
samtools depth dominette_merged_btau4.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
	2697640645
freebayes -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 2 -F 0.5 -b dominette_merged_btau4.bam -v dominette_merged_btau4.bayes.vcf -f /mnt/iscsi/vnx_gliu_7/reference/bosTau4.fa
perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < dominette_merged_btau4.bayes.vcf
	281999

perl -e '$ns = 281999; $nb = 2697640645; print (-10 * log($ns/$nb)/log(10)); print "\n";'
	39.8073652818702 # Btau4 qv

perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f dominette_merged_btau4_Features.txt -c 1
Entry   Count
COMPR_PE        6407
HIGH_COV_PE     4406
HIGH_NORM_COV_PE        3671
HIGH_OUTIE_PE   988
HIGH_SINGLE_PE  3247
HIGH_SPAN_PE    9240
LOW_COV_PE      135529
LOW_NORM_COV_PE 137377
STRECH_PE       16385

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < dominette_merged_btau4.lumpy.vcf | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        12870
DUPLICATION     1305
INTERCHROM      9031
INVERSION       2152

# Errors per 100 mbp = (25358 / 28.0) = 905.64

# umd3
samtools depth dominette.merged.umd3.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
	2633997017
freebayes -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 2 -F 0.5 -b dominette.merged.umd3.bam -v dominette.merged.umd3.bayes.vcf -f ../../../Genomes/Bos_taurus.UMD3.1.73.fa
perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < dominette.merged.umd3.bayes.vcf
	300091

perl -e '$ns = 300091; $nb = 2633997017; print (-10 * log($ns/$nb)/log(10)); print "\n";'
	39.4336230805122 # UMD3 qv

perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f dominette.merged.umd3_Features.txt -c 1
Entry   Count
COMPR_PE        12348
HIGH_COV_PE     7660
HIGH_NORM_COV_PE        7169
HIGH_OUTIE_PE   2303
HIGH_SINGLE_PE  1295
HIGH_SPAN_PE    4135
LOW_COV_PE      64527
LOW_NORM_COV_PE 67417
STRECH_PE       21891

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < dominette.merged.umd3.lumpy.vcf | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        13963
DUPLICATION     2493
INTERCHROM      8711
INVERSION       5470

# Errors per 100 mbp = (30637 / 28.0) = 1094.18


## Computomix
perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f canu/canu.dominette.topolish_Features.txt -c 1
Entry   Count
COMPR_PE        6526
HIGH_COV_PE     7333
HIGH_NORM_COV_PE        5759
HIGH_OUTIE_PE   80
HIGH_SINGLE_PE  118
HIGH_SPAN_PE    5982
LOW_COV_PE      52772
LOW_NORM_COV_PE 50719
STRECH_PE       16752

lumpy -mw 4 -tt 0 -pe id:sample,bam_file:canu.dominette.topolish.discordants.bam,histo_file:canu.dominette.topolish.histo,mean:628.478,stdev:168.47,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 -sr id:sample,bam_file:canu.dominette.topolish.splitters.bam,back_distance:10,min_mapping_threshold:20,weight:1,min_clip:20 > canu.dominette.topolish.lumpy.vcf

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < canu/canu.dominette.topolish.lumpy.vcf  | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        4272
DUPLICATION     320
INTERCHROM      2132
INVERSION       487


```

OK, let's summarize things:

| Feature | Btau4 | UMD3 | Serge | Aleksey |Description |
| :--- | ---: | ---: | ---: | ---: |:--- |
| QV | 39.80 | 39.43 | 32.78 | 38.85 | Phred-based assessment of INDEL and SNP errors in assembly |
| Errors / 100 Mbp | 905.64 | 1094.18 | 257 | 213.75 | Ratio of Lumpy SV calls per 100 Mbp |
| DELETION | 12870 | 13963 | 4272 | 1363 | Lumpy-SV deletions |
| DUPLICATION | 1305 | 2493 | 320 | 611 | Lumpy-SV duplications |
| INTERCHROM | 9031 |  8711 | 2132| 3943 | Lumpy-SV interchromosome regions |
| INVERSION | 2152 |  5470 | 487 | 68 | Lumpy-SV inversions |
|COMPR_PE         |   6407|12348| 6526| 9000 | Areas with low CE statistics |
|HIGH_COV_PE      |   4406|7660| 7333| 10098 | Higher read coverage |
|HIGH_NORM_COV_PE |   3671|7169| 5759 | 7944 | High coverage of normal paired-end reads |
|HIGH_OUTIE_PE    |    988|2303| 80| 79 | Regions with high numbers of misoriented or distant pairs |
|HIGH_SINGLE_PE   |   3247|1295| 118 | 251 |Regions with high numbers of unmapped pairs |
|HIGH_SPAN_PE     |   9240|4135| 5982 | 14180 |Regions with high numbers of disc. pairs that map to different scaffolds |
|LOW_COV_PE       | 135529|64527| 52772 | 100814 |Low read coverage |
|LOW_NORM_COV_PE  | 137377|67417| 50719 | 105271 |Low coverage of normal paired-end reads |
|STRECH_PE        |  16385|21891| 16752 | 15079 |Areas with high CE statistics |

<a name="polished"></a>
## Polished assembly

Now that we have the polished assembly back from Aleksey, it's time to process it.

```bash
module load bwa
module load samtools/1.3-20-gd49c73b

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="bwa index polished.fa"
sbatch --mem=2000 --nodes=1 --ntasks-per-node=1 --wrap="samtools faidx polished.fa"

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="java -Xmx19g -jar /mnt/nfs/nfs2/bickhart-users/binaries/GetMaskBedFasta/store/GetMaskBedFasta.jar -f polished.fa -o polished.gaps.bed -s polished.gaps.stats"
sbatch --nodes=1 --mem=2000 --ntasks-per-node=8 --wrap 'samtools merge -c -p --threads 8 polished.merged.dominette.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L001_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L002_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L003_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L004_001.bam'

sbatch --nodes=1 --ntasks-per-node=1 --mem=1000 --wrap='samtools index bwa-out/polished.merged.dominette.bam'
sbatch serge_script_oneshot.sh polished/bwa-out/polished.merged.dominette polished/polished.fa

# Lumpy failed because of weird scripting errors. Rerunning...
sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; samtools view polished.merged.dominette.bam | tail -n+100000 | /opt/agil_cluster/lumpy-sv-0.2.12-51-g16b6876/bin/../scripts/pairend_distro.py -r 150 -X 4 -N 10000 -o polished.merged.dominette.histo"

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; lumpy -mw 4 -tt 0 -pe id:dominette,bam_file:polished.merged.dominette.bam,histo_file:polished.merged.dominette.histo,mean:626.926292629,stdev:193.453829908,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 > polished.merged.dominette.lumpy.vcf"

./vcfToBedpe -i polished/bwa-out/polished.merged.dominette.lumpy.vcf -o polished/bwa-out/polished.merged.dominette.lumpy.bedpe

perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < polished.merged.dominette.bayes.vcf
353921
samtools depth polished.merged.dominette.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
2720125193
perl -e 'chomp(@ARGV); $ns = $ARGV[0]; $nb = $ARGV[1]; print (-10 * log($ns/$nb)/log(10)); print "\n";' 353921 2720125193
38.8568256039133

# Checking to see if the SNPs and indels correspond to lumpy SV calls
# Pulling lumpy calls into beds and then pulling only the >65% AB percentile variants from the freebayes output
perl -lane 'if($F[0] =~ /^#/){next;} if($F[1] < 0){ $F[1] = 0;} if($F[3] < 0){$F[3] = 0;} if($F[10] eq "BND"){print "$F[0]\t$F[1]\t$F[2]\t$F[10]"; print "$F[3]\t$F[4]\t$F[5]\t$F[10]";}else{print "$F[0]\t$F[1]\t$F[5]\t$F[10]";}' < polished.merged.dominette.lumpy.bedpe > polished.merged.dominette.lumpy.bed
perl -lane 'if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;} $e = $F[1] + 1; print "$F[0]\t$F[1]\t$e";' < polished.merged.dominette.bayes.vcf > polished.merged.dominette.bayes.bed
intersectBed -a polished.merged.dominette.lumpy.bed -b polished.merged.dominette.bayes.bed -c | perl -lane 'if($F[4] > 0){print $_;}' | wc -l
2417   <- total SNPs/INDELs within lumpy predicted discordant regions (~24% of total)
perl -lane 'if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;} $e = $F[1] + 1; print "$F[0]\t$F[1]\t$e";' < polished.merged.dominette.bayes.vcf > polished.merged.dominette.bayes.bed
[dbickhart@vm-agil-251-fry bwa-out]$ intersectBed -a polished.merged.dominette.lumpy.bed -b polished.merged.dominette.bayes.bed -c | perl -lane 'if($F[4] > 0){print $_;}' | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 3 -m
```
### Variants within lumpy sv coordinates in polished assembly
|Entry | Count|
|:-----|-----:|
|BND   |  1436|
|DEL   |   506|
|DUP   |   432|
|INV   |    43|


<a name="ctx"></a>
## Computomix assembly

The polished assembly looks corrupted... I'm going to run a comparison with the real computomix assembly to see how that panned out.

> fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/ctx

```bash
sh create_bwa_batchfiles.sh dominette_nextseq_file_list.tab
sbatch --nodes=1 --ntasks-per-node=2 --mem=10000 --wrap="module load bwa; module load samtools; bwa index CTX3.fasta; samtools faidx CTX3.fasta"

sleep 3h; find batchfiles-bwa/ -name *.sh | xargs -I {} sbatch {}
sbatch --nodes=1 --ntasks-per-node=10 --mem=5000 --wrap="module load samtools/1.3-20-gd49c73b; samtools merge -c -p -@ 9 polishedAsm.NextSeq.dominette.merged.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L001_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L002_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L003_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L004_001.bam; samtools index polishedAsm.NextSeq.dominette.merged.bam;"

sbatch ../serge_script_oneshot.sh bwa-out/polishedAsm.NextSeq.dominette.merged CTX3.fasta dominette
```

## Other assemblies

Aleksey made two additional assemblies that need to be run through the pipeline.

> fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/

```bash
#### Polished.final ####
mkdir polished.final
cd polished.final

sbatch --nodes=1 --mem=6000 --ntasks-per-node=1 --wrap="module load bwa; module load samtools; wget ftp://ftp.genome.umd.edu/pub/dominette/polished.final.fa.gz; gunzip polished.final.fa.gz; bwa index polished.final.fa; samtools faidx polished.final.fa;"

perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b alignments -t ../dominette_nextseq_file_list.tab -f polished.final.fa -m
sbatch serge_script_oneshot.sh polished.final/alignments/dominette/dominette.sorted.merged polished.final/polished.final.fa dominette

#### Topolish no 1b ####
mkdir topolish.no1b
cd topolish.no1b

sbatch --nodes=1 --mem=6000 --ntasks-per-node=1 --wrap="module load bwa; module load samtools; wget ftp://ftp.genome.umd.edu/pub/dominette/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta.gz; gunzip topolish.filledWithCanuAndPBJelly.withX.no1b.fasta.gz; bwa index topolish.filledWithCanuAndPBJelly.withX.no1b.fasta; samtools faidx topolish.filledWithCanuAndPBJelly.withX.no1b.fasta;"

perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b alignments -t ../dominette_nextseq_file_list.tab -f topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -m
sbatch serge_script_oneshot.sh topolish.no1b/alignments/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta dominette

# Damn, I suspect that Slurm automatically kills jobs that post with an ampersand. Going to queue up FRC and lumpy using separate commands
sbatch --nodes=1 --ntasks-per-node=2 --mem=25000 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; lumpy -mw 4 -tt 0  -pe id:dominette,bam_file:topolish.no1b/alignments/dominette/dominette.sorted.merged.discordants.bam,histo_file:topolish.no1b/alignments/dominette/dominette.sorted.merged.histo,mean:626.861177885,stdev:184.997331276,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 > topolish.no1b/alignments/dominette/dominette.sorted.merged.lumpy.2.vcf"
sbatch --nodes=1 --ntasks-per-node=2 --mem=25000 --wrap="module load FRC_align/1.3.0-5b3f53e; FRC  --pe-sam topolish.no1b/alignments/dominette/dominette.sorted.merged.bam --pe-max-insert 1181 --genome-size 2800000000 --output topolish.no1b/alignments/dominette/dominette.sorted.merged.2"

sbatch --nodes=1 --ntasks-per-node=2 --mem=25000 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; lumpy -mw 4 -tt 0  -pe id:dominette,bam_file:polished.final/alignments/dominette/dominette.sorted.merged.discordants.bam,histo_file:polished.final/alignments/dominette/dominette.sorted.merged.histo,mean:666.1878,stdev:182.802370146,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 > polished.final/alignments/dominette/dominette.sorted.merged.lumpy.2.vcf"
```

#### Update of stats table

| Feature | Btau4 | UMD3 | Serge | Aleksey | polished.final | topolish.no1b |Description |
| :--- | ---: | ---: | ---: | ---: | ---: | ---: |:--- |
| QV | 39.80 | 39.43 | 32.78 | 38.85 | 38.23 | 40.87 |Phred-based assessment of INDEL and SNP errors in assembly |
| Errors / 100 Mbp | 905.64 | 1094.18 | 257 | 213.75 | | | Ratio of Lumpy SV calls per 100 Mbp |
| DELETION | 12870 | 13963 | 4272 | 1363 | | | Lumpy-SV deletions |
| DUPLICATION | 1305 | 2493 | 320 | 611 | | | Lumpy-SV duplications |
| INTERCHROM | 9031 |  8711 | 2132| 3943 | | | Lumpy-SV interchromosome regions |
| INVERSION | 2152 |  5470 | 487 | 68 | | | Lumpy-SV inversions |
|COMPR_PE         |   6407|12348| 6526| 9000 | 68847 | 174622 | Areas with low CE statistics |
|HIGH_COV_PE      |   4406|7660| 7333| 10098 | 10320 | 7214 | Higher read coverage |
|HIGH_NORM_COV_PE |   3671|7169| 5759 | 7944 | 8185 | 5481 | High coverage of normal paired-end reads |
|HIGH_OUTIE_PE    |    988|2303| 80| 79 | 133 | 122 | Regions with high numbers of misoriented or distant pairs |
|HIGH_SINGLE_PE   |   3247|1295| 118 | 251 | 306 | 92 | Regions with high numbers of unmapped pairs |
|HIGH_SPAN_PE     |   9240|4135| 5982 | 14180 | 14993 | 5166 | Regions with high numbers of disc. pairs that map to different scaffolds |
|LOW_COV_PE       | 135529|64527| 52772 | 100814 | 107927 | 58672 | Low read coverage |
|LOW_NORM_COV_PE  | 137377|67417| 50719 | 105271 | 111927 | 57701 | Low coverage of normal paired-end reads |
|STRECH_PE        |  16385|21891| 16752 | 15079 | 39885 | 94925 | Areas with high CE statistics |


Now to generate a FRC curve to compare stats.

```R
data.serge <- read.delim("canu/canu.dominette.topolish_FRC.txt", sep=" ", header=FALSE)
data.aleksey <- read.delim("polished/bwa-out/polished.merged.dominette_FRC.txt", sep=" ", header=FALSE)
data.topolish <- read.delim("topolish.no1b/alignments/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.final <- read.delim("polished.final/alignments/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
pdf(file="frc_curve_fourasms.pdf", useDingbats=FALSE)

plot(data.serge$V1, data.serge$V2, type="l", col="red")
lines(data.aleksey$V1, data.aleksey$V2, col="green")
lines(data.topolish$V1, data.topolish$V2, col="blue")
lines(data.final$V1, data.final$V2, col="brown")
legend("topleft", legend = c("Serge", "Aleksey1", "Aleksey2", "topolishNob1"), col = c("red", "green", "blue", "brown"))
dev.off()

pdf(file="frc_curve_threeasms.pdf", useDingbats=FALSE)
plot(data.aleksey$V1, data.aleksey$V2, col="green", type="l")
lines(data.topolish$V1, data.topolish$V2, col="blue")
lines(data.final$V1, data.final$V2, col="brown")
legend("topleft", legend = c("Aleksey1", "Aleksey2", "topolishNoB1"), lty=c(1,1), lwd=c(2,2), col = c("green", "blue", "brown"))

```

Rerunning only on run2 data

```bash
mkdir run2only
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b umd3 -t ../dominett_run2_only_files.tab -f /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b canu -t ../dominett_run2_only_files.tab -f ../canu/topolish.filledWithCanuAndPBJelly.fasta -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b ctx -t ../dominett_run2_only_files.tab -f ../ctx/CTX3.fasta -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b polished -t ../dominett_run2_only_files.tab -f ../polished/polished.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b polished.final -t ../dominett_run2_only_files.tab -f ../polished.final/polished.final.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b topolish.no1b -t ../dominett_run2_only_files.tab -f ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -m

sbatch serge_script_oneshot.sh run2only/canu/dominette/dominette.sorted.merged canu/topolish.filledWithCanuAndPBJelly.fasta dominette
sbatch serge_script_oneshot.sh run2only/ctx/dominette/dominette.sorted.merged ctx/CTX3.fasta dominette
sbatch serge_script_oneshot.sh run2only/umd3/dominette/dominette.sorted.merged /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa dominette
sbatch serge_script_oneshot.sh run2only/polished/dominette/dominette.sorted.merged polished/polished.fa dominette
sbatch serge_script_oneshot.sh run2only/polished.final/dominette/dominette.sorted.merged polished.final/polished.final.fa dominette
sbatch serge_script_oneshot.sh run2only/topolish.no1b/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta dominette
```

Rerunning only on run1 data

```bash
mkdir run1only
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b umd3 -t ../dominette_run1_only_nextseq_file_list.tab -f /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b canu -t ../dominette_run1_only_nextseq_file_list.tab -f ../canu/topolish.filledWithCanuAndPBJelly.fasta -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b ctx -t ../dominette_run1_only_nextseq_file_list.tab -f ../ctx/CTX3.fasta -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b polished -t ../dominette_run1_only_nextseq_file_list.tab -f ../polished/polished.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b polished.final -t ../dominette_run1_only_nextseq_file_list.tab -f ../polished.final/polished.final.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b topolish.no1b -t ../dominette_run1_only_nextseq_file_list.tab -f ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -m

# Running all of the diagnostic scripts as dependent jobs
sbatch --dependency=afterok:656252 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/topolish.no1b/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta dominette
sbatch --dependency=afterok:656247 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/polished.final/dominette/dominette.sorted.merged polished.final/polished.final.fa dominette
sbatch --dependency=afterok:656242 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/polished/dominette/dominette.sorted.merged polished/polished.fa dominette
sbatch --dependency=afterok:656237 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/ctx/dominette/dominette.sorted.merged ctx/CTX3.fasta dominette
sbatch --dependency=afterok:656232 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/canu/dominette/dominette.sorted.merged canu/topolish.filledWithCanuAndPBJelly.fasta dominette
sbatch --dependency=afterok:656227 serge_script_oneshot.sh /mnt/nfs/nfs2/dbickhart/dominette_asm/run1only/umd3/dominette/dominette.sorted.merged /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa dominette

for i in `ls run1only/*/dominette/dominette.sorted.merged.lumpy.vcf`; do dir=`dirname $i`; echo $dir; ./vcfToBedpe -i $i -o $dir/dominette.sorted.merged.lumpy.bedpe; done
perl ../../bickhart-users/binaries/GoatAssemblyScripts/assembly_frc_benchmarking/summarizeAnalysisSlurm.pl -b run1only/canu/dominette/dominette.sorted.merged,run1only/ctx/dominette/dominette.sorted.merged,run1only/polished/dominette/dominette.sorted.merged,run1only/polished.final/dominette/dominette.sorted.merged,run1only/topolish.no1b/dominette/dominette.sorted.merged,run1only/umd3/dominette/dominette.sorted.merged -n canu,ctx,polished,polished.final,topolish.no1b,umd3 -o slurm_summary_stats_run2only.md
```

|Entry            | canu | ctx |polished|p.final|topolish.no1b| umd3|
|:----------------|-----:|-----:|-----:|-----:|-----:|-----:|
|BND              |  3157|   842|  4077|  3298|  2681| 13258|
|INV              |    85|    83|   110|    99|    73|  2157|
|DEL              |  1593|  1348|  2159|  2013|  1491| 12069|
|DUP              |   450|   458|  1120|  1202|   439|  3222|
|HIGH_COV_PE      |  7419|  7498|  9743|  9844|  7234|  6605|
|HIGH_NORM_COV_PE |  5567|  5573|  7581|  7656|  5464|  5849|
|HIGH_OUTIE_PE    |    85|    41|    80|    95|    90|  2280|
|HIGH_SINGLE_PE   |   191|   242|   234|   253|    83|  1289|
|HIGH_SPAN_PE     |  9926|  9480| 13695| 13784|  4986|  3959|
|LOW_COV_PE       | 42779| 36226| 75878| 76200| 55912| 50934|
|LOW_NORM_COV_PE  | 41385| 34820| 82166| 82693| 55203| 55638|
|STRECH_PE        | 27257| 25495| 26656| 25697| 27470| 28936|
|COMPR_PE         | 13937| 17704| 28604| 24878| 14454| 22221|
|QV               |    41|    41|    40|    40|    41|    41|


Plotting the data in an FRC curve in R

```R
data.canu <- read.delim("run1only/canu/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.ctx <- read.delim("run1only/ctx/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.polished <- read.delim("run1only/polished/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.polished.final <- read.delim("run1only/polished.final/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.topolish.no1b <- read.delim("run1only/topolish.no1b/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.umd3 <- read.delim("run1only/umd3/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)

pdf(file="frc_curve_run1only_data_frc.pdf", useDingbats=FALSE)

plot(data.canu$V1, data.canu$V2, type="l", col="red")
lines(data.ctx$V1, data.ctx$V2, col="blue")
lines(data.polished$V1, data.polished$V2, col="green")
lines(data.polished.final$V1, data.polished.final$V2, col="brown")
lines(data.topolish.no1b$V1, data.topolish.no1b$V2, col="purple")
lines(data.umd3$V1, data.umd3$V2, col="orange")
legend("topleft", legend = c("canu", "ctx", "polished", "polished.final", "topolish.no1b", "umd3"), lty=c(1,1), lwd=c(2,2), col=c("red", "blue", "green", "brown", "purple", "orange"))

dev.off()
```

OK our decision was to go with the topolish.no1b assembly.

<a name="recomb"></a>
## Recombination map alignment and problem region identification 

Using the recombination map information, I need to remap probes and identify breakpoints in order. Bob has data on his comparisons with the linkage map he has in his database. Both the recombination map and linkage map are highly similar, so they are all but interchangeable. I am going to remap probes and identify the major breakpoints.

First things first, let's extract the fasta sequence from the manifest file.

> Fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/recombination

```bash
perl -e 'for(my $x = 0; $x < 8; $x++){<>;} while(<>){chomp; @s = split(/,/); print ">$s[1].$s[9].$s[10]\n$s[5]\n";}' < rcmap_manifest.csv > rcmap_manifest.fa

sbatch alignAndOrderSnpProbes.pl -a ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -p rcmap_manifest.fa -o rcmap_test_run_topolish.no1b

# Testing canu alignments on topolish:
perl alignAndOrderSnpProbes.pl -n toPolishVsCanu.long1coords -o toPolishVsCanuTest

# Identifying regions that have zero read coverage in topolish
sbatch --nodes=1 --mem=20000 --ntasks-per-node=1 --wrap="module load bedtools/2.25.0; bedtools genomecov -ibam topolish.no1b/alignments/dominette/dominette.sorted.merged.bam -g topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -d | perl -lane 'if($F[2] == 0){print $_;}' > topolish.no1b/topolish.no1b.bases_zero_cov.tab"

perl condense_zero_cov_regions.pl topolish.no1b.cov.tab topolish.no1b.bases_zero_cov.bed

sbatch --nodes=1 --mem=10000 --ntasks-per-node=2 --wrap="module load java/jdk1.8.0_92; java -Xmx10g -jar ../../../bickhart-users/binaries/GetMaskBedFasta/store/GetMaskBedFasta.jar -f topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -o topolish.filledWithCanuAndPBJelly.withX.no1b.gaps.bed -s topolish.filledWithCanuAndPBJelly.withX.no1b.gaps.stats"

# Removing zero coverage bases under 5bp (most indels
perl -lane 'if($F[2] - $F[1] > 5){print $_;}' < topolish.no1b.bases_zero_cov.bed > topolish.no1b.bases_zero_cov.gt5bp.bed
wc -l topolish.no1b.bases_zero_cov.bed topolish.no1b.bases_zero_cov.gt5bp.bed
  97988 topolish.no1b.bases_zero_cov.bed
  74211 topolish.no1b.bases_zero_cov.gt5bp.bed

intersectBed -a topolish.filledWithCanuAndPBJelly.withX.no1b.gaps.bed -b topolish.no1b.bases_zero_cov.gt5bp.bed -wa | wc -l
521 <- that's all 520 gaps + some bases on the side

intersectBed -a topolish.no1b.bases_zero_cov.gt5bp.bed -b topolish.filledWithCanuAndPBJelly.withX.no1b.gaps.bed -v > topolish.no1b.bases_zero_cov.gt5bp.nogaps.bed

wc -l topolish.no1b.bases_zero_cov.gt5bp.nogaps.bed
	73690 topolish.no1b.bases_zero_cov.gt5bp.nogaps.bed  <- thats 74211 zero cov - 521 gaps

# Dammit! The coordinates in the manifest file are for UMD3, not the rc map!
# Correcting it
perl -e 'chomp(@ARGV); my %h; open($IN, "< $ARGV[0]"); <$IN>; while(<$IN>){chomp; @s = split(/,/); $h{$s[0]} = [$s[1], $s[2]];} close $IN; open($IN, "< $ARGV[1]"); for(my $x = 0; $x < 8; $x++){<$IN>;} while(<$IN>){chomp; @s = split(/,/); if(exists($h{$s[1]})){$chr = $h{$s[1]}->[0]; $pos = $h{$s[1]}->[1]; print ">$s[1].$chr.$pos\t$s[5]\n";}else{print ">$s[1].$s[9].$s[10]\t$s[5]\n";}}' /mnt/nfs/nfs2/dbickhart/dominette_asm/recombination/rcmap_hits.csv /mnt/nfs/nfs2/dbickhart/dominette_asm/recombination/rcmap_manifest.csv | perl -e '%d; while($l = <>){chomp $l; @s = split(/\t/, $l); @n = split(/\./, $s[0]); $d{$n[1]}->{$n[2]} = $l;} foreach my $chr (sort{$a <=> $b} keys(%d)){foreach my $pos (sort{$a <=> $b} keys(%{$d{$chr}})){ @h = split(/\t/, $d{$chr}->{$pos}); print "$h[0]\n$h[1]\n";}}' > /mnt/nfs/nfs2/dbickhart/dominette_asm/recombination/rcmap_manifest_correct.sorted.fa

```


#### condense_zero_cov_regions.pl
```perl
#!/usr/bin/perl
# A quick one-shot script designed to process a bedtools coverage bed file to identify regions of zero coverage

my $usage = "perl $0 <input bedtools coverage tab> <output zero coverage bed>\n";

chomp(@ARGV);

open(my $IN, "< $ARGV[0]") || die "$usage";
open(my $OUT, "> $ARGV[1]");
my $chr = "NA"; my $start = 0; my $end = 0; my $inzero = 0;

my $h = <$IN>;
chomp $h; my @first = split(/\t/, $h);
$chr = $first[0];
while(my $line = <$IN>){
        chomp $line;
        my @segs = split(/\t/, $line);
        if($segs[0] ne $chr){
                if($inzero){
                        print {$OUT} "$chr\t$start\t$end\n";
                        $inzero = 0;
                        $start = 0; $end = 0;
                }
                $chr = $segs[0];
        }elsif($inzero && $segs[2] != 0){
                print {$OUT} "$chr\t$start\t$end\n";
                $inzero = 0;
                $start = 0; $end = 0;
        }elsif($segs[2] == 0 && !$inzero){
                $inzero = 1;
                $start = $segs[1];
                $end = $segs[1];
        }elsif($inzero){
                $end = $segs[1];
        }
}
close $IN;

if($inzero){
        print {$OUT} "$chr\t$start\t$end\n";
}
close $OUT;
exit;
```

<a name="longrange"></a>
## Fixing longrange issues in cattle asms

Aleksey used Bob's guides to correct the misplaced contigs on topolish.no1b. I'm going to run his assemblies through the pipeline to see how they stack up.

> /mnt/nfs/nfs2/dbickhart/dominette_asm/revised_sv_cattle_asms

```bash
sbatch --nodes=1 --mem=6000 --ntasks-per-node=1 --wrap="module load bwa; module load samtools; wget ftp://ftp.genome.umd.edu/pub/dominette/topolish.filledWithCanuAndPBJelly.withX.no1b.4rev.6rev.8fix.7rev.9fix.11fix.13rev.14rev.16fix.16rev.18rev.19rev.20fix.21fix.23fix.24rev.26fix.29rev.fasta; mv topolish.filledWithCanuAndPBJelly.withX.no1b.4rev.6rev.8fix.7rev.9fix.11fix.13rev.14rev.16fix.16rev.18rev.19rev.20fix.21fix.23fix.24rev.26fix.29rev.fasta topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa; bwa index topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa; samtools faidx topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa"

sbatch --nodes=1 --mem=1000 --ntasks-per-node=1 --dependency=afterok:656502 --wrap="perl /mnt/nfs/nfs2/bickhart-users/binaries/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b nosplit -t ../dominette_run1_only_nextseq_file_list.tab -f topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa -m"

sbatch --nodes=1 --mem=6000 --ntasks-per-node=1 --wrap="module load bwa; module load samtools; wget ftp://ftp.genome.umd.edu/pub/dominette/topolish.filledWithCanuAndPBJelly.withX.no1b.4rev.6rev.8fix.7rev.9fix.11fix.13rev.14rev.16fix.16rev.18rev.19rev.20fix.21fix.23fix.24rev.26fix.29rev.split.fasta; mv topolish.filledWithCanuAndPBJelly.withX.no1b.4rev.6rev.8fix.7rev.9fix.11fix.13rev.14rev.16fix.16rev.18rev.19rev.20fix.21fix.23fix.24rev.26fix.29rev.split.fasta topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa; bwa index topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa;  samtools faidx topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa"

sbatch --nodes=1 --mem=1000 --ntasks-per-node=1 --dependency=afterok:656504 --wrap="perl /mnt/nfs/nfs2/bickhart-users/binaries/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b split -t ../dominette_run1_only_nextseq_file_list.tab -f topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa -m"

sbatch serge_script_oneshot.sh topolish.no1b/nosplit/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa dominette
sbatch --nodes=1 --mem=15000 --ntasks-per-node=1 --wrap="module load bedtools/2.25.0; bedtools genomecov -ibam topolish.no1b/nosplit/dominette/dominette.sorted.merged.bam -bga > topolish.no1b/nosplit/dominette/dominette.sorted.merged.bedtools.cov.tab"

sbatch --dependency=afterok:656510 serge_script_oneshot.sh topolish.no1b/split/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa dominette

sbatch --mem=2000 --nodes=1 --ntasks-per-node=1 --wrap="perl -lane 'if($F[3] == 0){print $_;}' < nosplit/dominette/dominette.sorted.merged.bedtools.cov.tab > nosplit/dominette/dominette.sorted.merged.bedtools.zero.cov.tab"
```

OK, I now need to correct chromosome 6 as that was the remaining error after Serge and Bob's manual edits.

From Bob's slack post:

> btw @dbickhart if you want to fix chr6, just replace the scaffold in aleksey's topolish from about position 113620307 to the end with canu contig tig00001238 and make the scaffold 6 start at 16698095

Serge:

> 113162819
this seems to be my last good position 
before it jumps to the 1238 tig

From the long1coords that Serge provided, it looked like tig00001238 should be aligned in reverse to the start of the 109,733,389 portion of chr6. Also, to avoid duplicating the contig, I need to remove up to the 4,651,327 bp in the beginning. I will check alignments of reads to confirm both. I need to be careful!!! The coordinates on the nucmer plot are reversed! I will check with a brief alignment of the "ends" of tig0001238 to make sure.

Another issue is chromosome X. From the alignments of Canu contigs to ChrX, it looks like there is a huge "gap" in Aleksey's X chromosome that spans tig00009294. There is also a section of tig00001361 that appears to be a "gap" in Aleksey's X. Finally, tig00001577 has an inversion. I'm going to check against the X chr mapping probes first and then align reads to each contig to check.

```bash
# mapping to Canu mhap asm
sbatch --nodes=1 --mem=20000 --ntasks-per-node=2 --wrap="module load bwa; bwa index canu.mhap.all.fasta; perl recombination/alignAndOrderSnpProbes.pl -a canu.mhap.all.fasta -p recombination/rcmap_manifest.fa -o recombination/canu.mhap.rcmap"

# Grepping contigs that I need for alignment
mkdir rdcheck
samtools faidx canu.mhap.all.fasta tig00001238 tig00009294 tig00001361 tig00001577 > rdcheck/canu_tigs_1238_9294_1361_1577.fa
sbatch --nodes=1 --mem=5000 --ntasks-per-node=1 --wrap="module load bwa; bwa index rdcheck/canu_tigs_1238_9294_1361_1577.fa"


# Fixing chr6
mkdir chr_fixing
# Testing hypothesis on contig coordinates
bwa mem topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa chr_fixing/tig00001238_orientation.fa > chr_fixing/tig00001238_orientation.sam
	tig00001238:1-1000      16      6       4650322 60
	# So the long coord file I have is correct. 	
	# remove topolish6:97,358,809-end
	# tig00001238:4684386-end  orient:-   needs to go on the beginning of the chr6 scaffold
	# tig00009764:1-end orient:- needs to go on the end of the chr6 scaffold
	
# Starting the process
samtools faidx topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa 6:1-97358809 > chr_fixing/topolish.fixed.chr6.1_97mb.fa
samtools faidx canu.mhap.all.fasta tig00001238:4684386-20561998 > chr_fixing/tig00001238_segment.fa
samtools faidx canu.mhap.all.fasta tig00009764:1-1716403 > chr_fixing/tig00009764_segment.fa

sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i tig00001238_segment.fa,topolish.fixed.chr6.1_97mb.fa,tig00009764_segment.fa -d '-,+,-' -o topolish.fixed.chr6.fixed.fa"

# Testing
samtools faidx topolish.fixed.chr6.fixed.fa 6:1000-2000 6:4000-5000 6:100000000-100001000 6:100003000-100004000 > new_chr6_test.fa
bwa mem ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa new_chr6_test.fa > new_chr6_test.sam
# So far, so good!


# Whoops! Hold the phone! Now I know why tig00009764 was broken up -- it has a misassembly with chr17 in the middle
# Just confirmed with alignment images and the recombination map
samtools faidx ../canu.mhap.all.fasta tig00009764:1-503775 > tig00009764_broken_segment2.fa
samtools faidx ../canu.mhap.all.fasta tig00009764:646287-1716403 > tig00009764_broken_segment1.fa
sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i tig00001238_segment.fa,topolish.fixed.chr6.1_97mb.fa,tig00009764_broken_segment1.fa,tig00009764_broken_segment2.fa -d '-,+,-,-' -o topolish.fixed.chr6.fixed.tig9764.fa"

# Testing the recombination map to determine if the chr is assembled correctly
sbatch --nodes=1 --mem=20000 --ntasks-per-node=2 --wrap="module load bwa; bwa index canu.mhap.all.fasta; perl recombination/alignAndOrderSnpProbes.pl -a topolish.fixed.chr6.fixed.tig9764.fa -p ../recombination/rcmap_manifest.fa -o topolish.fixed.chr6.fixed.tig9764.rcmap"

# OK, now to generate the final fasta
sbatch --nodes=1 --mem=20000 --ntasks-per-node=2 --wrap="module load bwa; bwa index topolish.fixed.chr6.fixed.tig9764.fa; perl ../recombination/alignAndOrderSnpProbes.pl -a topolish.fixed.chr6.fixed.tig9764.fa -p ../recombination/rcmap_manifest.fa -o topolish.fixed.chr6.fixed.tig9764.rcmap"

# There appears to be a flaw within tig00001238. Going to try to fix it quickly
	6       107394629       107585442       6       12834838        12636238        -       190813  198600
	6       107678393       108677334       6       2197697 1249100 -       998941  948597
	6       108756884       109835444       6       61567   1169965 +       1078560 1108398
	6       109951981       114580517       6       12501415        7908900 -       4628536 4592515

samtools faidx topolish.fixed.chr6.fixed.tig9764.fa 6:2197697-12636238 > topolish.fixed.chr6.fixed.tig9764.seg1.fa
samtools faidx topolish.fixed.chr6.fixed.tig9764.fa 6:1-1169965 > topolish.fixed.chr6.fixed.tig9764.seg2.fa
samtools faidx topolish.fixed.chr6.fixed.tig9764.fa 6:1249100-2197697 > topolish.fixed.chr6.fixed.tig9764.seg3.fa
samtools faidx topolish.fixed.chr6.fixed.tig9764.fa 6:12636238-114810314 > topolish.fixed.chr6.fixed.tig9764.seg4.fa

sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i topolish.fixed.chr6.fixed.tig9764.seg1.fa,topolish.fixed.chr6.fixed.tig9764.seg2.fa,topolish.fixed.chr6.fixed.tig9764.seg3.fa,topolish.fixed.chr6.fixed.tig9764.seg4.fa -d '+,-,+,+' -o topolish.fixed.chr6.fixed.tig9764.resegment.fa"

sbatch --nodes=1 --mem=20000 --ntasks-per-node=2 --wrap="module load bwa; bwa index topolish.fixed.chr6.fixed.tig9764.resegment.fa; perl ../recombination/alignAndOrderSnpProbes.pl -a topolish.fixed.chr6.fixed.tig9764.resegment.fa -p ../recombination/rcmap_manifest.fa -o topolish.fixxed.chr6.fixed.tig9764.resegment.rcmap"


# Parity checking with UMD3
sbatch /mnt/nfs/nfs2/bickhart-users/binaries/perl_toolchain/assembly_scripts/rapidAssemblyChrAlignmentComp.pl -c /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa -j chr6 -n chr_fixing/topolish.fixed.chr6.fixed.tig9764.fa -m 6 -o chr_fixing/chr6.fixed.tig9764.umd3.comp.tab
sbatch /mnt/nfs/nfs2/bickhart-users/binaries/perl_toolchain/assembly_scripts/rapidAssemblyChrAlignmentComp.pl -c /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa -j chr6 -n chr_fixing/topolish.fixed.chr6.fixed.tig9764.resegment.fa -m 6 -o chr_fixing/chr6.fixed.tig9764.resegment.umd3.comp.tab

```

Testing chr6 joining site locally

> pwd: 

```bash
perl -lane 'if($F[-1] == 6 && $F[0] >= 103583644 ){print "$F[0]\t$F[1]\t$F[2]\t$F[3]\t$F[-2]\t$F[-1]";}' < toPolishFixedVsUMD.long1coords | perl -e '$c = 99999999999; while(<>){chomp; @s = split(/\t/); if($s[2] < $c){$c = $s[2];} if($s[3] < $c){$c = $s[3]}} print "$c\n";'
101,794,133 <- lowest coordinate on chr6 topolish that maps before the break in UMD3

# Canu alignments in the region
# canu start	end				topolishstart	end				canu		topolish
#4430139		 4636418 		207602  		1196    		tig00001238     6
#4684386		 4778294 		109732733       109638725       tig00001238     6
#12438116        12589926        101927289       101775379       tig00001238     6
#12602754        12661935        101762438       **101703071**       tig00001238     6

# Decision time! I'm going to clip at the canu alignment point because: 
# (A) it's further down the scaffold and (b) it is the first point on the scaffold that encompasses the contig

# New info on the scaffold:
grep 'tig00009764' toPolishFixedVsCanu.long1coords
17195   243277  97874325        97647946        226083  226380  99.69   1716403 118271633       13.17   0.19    tig00009764     6
253491  353408  97637095        97536971        99918   100125  99.69   1716403 118271633       5.82    0.08    tig00009764     6
371604  530882  97518207        97358809        159279  159399  99.84   1716403 118271633       9.28    0.13    tig00009764     6
516824  640797  68269511        68145464        123974  124048  99.77   1716403 73196606        7.22    0.17    tig00009764     17
641983  752892  101420619       101309680       110910  110940  99.96   1716403 118271633       6.46    0.09    tig00009764     6
759484  914975  101303111       101147546       155492  155566  99.92   1716403 118271633       9.06    0.13    tig00009764     6
922504  1045799 101140028       101016649       123296  123380  99.89   1716403 118271633       7.18    0.10    tig00009764     6
1064989 1678373 100997497       100383750       613385  613748  99.87   1716403 118271633       35.74   0.52    tig00009764     6

# OK, so tig00009764 looks to be better. I'll start my clipping at the 97358809 start site instead
```

Bob sent a huge linkage map file. I'm going to reorder and reorganize the assembly based on that information and Aleksey's "split" ASM instead. This will keep things tidy and easier to resolve downstream.


> fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/bob_reorder

```bash
sbatch ../recombination/alignAndOrderSnpProbes.pl -a ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa -p ../recombination/rcmap_manifest.fa -o topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.rcmap

perl -ne 'if($_ =~ /^>/){$_ =~ s/\:/\_/g; print $_;}else{print $_;}' <  ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.split.fa > topolish.fixed.split.fa

# Chr6 
# 6:9 -, 6:11 -, 6:7 -, 6:5 -, 6:4 -, 6:3 -, 6:2 -, 6:1 -, 6:16 -, 6:15 -, 6:17 -, 
# The inversion is on 6:17, so I can fix it there or post creation
# In the folder, each chr 6 "segment" from the split fasta is represented by a "segment" fasta

sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i chr6_seg9.fa,chr6_seg11.fa,chr6_seg7.fa,chr6_seg5.fa,chr6_seg4.fa,chr6_seg3.fa,chr6_seg2.fa,chr6_seg1.fa,chr6_seg16.fa,chr6_seg15.fa,chr6_seg17.fa -d '-,-,-,-,-,-,-,-,-,-,-' -o chr6_correctlkrh_order.fa"

# That failed miserably! The lc map is missing several segments of chr6. Far better for me to salvage the previous version
# segments: tig00001238:1-7642766  tig00001238:17422149-18185848 tig00001238:7747445-7925712 tig00001238:18364253-19312850 tig00001238:20500383-19391985 -, tig00001238:8060536-17357033
samtools faidx canu.mhap.all.fasta tig00001238:4684386-7642766 > chr_fixing/tig1238_seg1.fa
samtools faidx canu.mhap.all.fasta tig00001238:17422149-18185848 > chr_fixing/tig1238_seg2.fa
samtools faidx canu.mhap.all.fasta tig00001238:7747445-7925712 > chr_fixing/tig1238_seg3.fa
samtools faidx canu.mhap.all.fasta tig00001238:18364253-19312850 > chr_fixing/tig1238_seg4.fa
samtools faidx canu.mhap.all.fasta tig00001238:19391985-20500383 > chr_fixing/tig1238_seg5.fa
samtools faidx canu.mhap.all.fasta tig00001238:8060536-17357033 > chr_fixing/tig1238_seg6.fa

sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i chr6_order_list.tab -o topolish.fixed.chr6.remapinv.fa -p 100"
sbatch process_and_qv_fasta.sh topolish.fixed.chr6.remapinv.fa
# Looks good, but the entire chromosome needs to be inverted. Going to do that

# Chr16
# There is a piece of the telomere that needs to be replaced
# Going to try to finemap it with the recombination map
samtools faidx ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa 16 > topolish.unfixed.chr16.fa
sbatch run_rcmap_only.sh topolish.unfixed.chr16.fa
# segments: 16:1-48410975 16:48796030-80254284 16:48411025-48594326
samtools faidx topolish.unfixed.chr16.fa 16:1-48410975 > chr16_seq1.fa
samtools faidx topolish.unfixed.chr16.fa 16:48796030-80254284 > chr16_seq2.fa
samtools faidx topolish.unfixed.chr16.fa 16:48411025-48594326 > chr16_seq3.fa

sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i chr16_order_list.tab -o topolish.fixed.chr16.revmap.fa -p 100"
sbatch --dependency=afterok:658056 process_and_qv_fasta.sh topolish.fixed.chr16.revmap.fa

# Chr20
# There is a small portion that needs to be remapped 
samtools faidx ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa 20 > topolish.unfixed.chr20.fa
sbatch run_rcmap_only.sh topolish.unfixed.chr20.fa
# Bob was right, looks like an inversion too
# segments: 20:373977-25698557, 20:1-373976 -, 20:25803664-71933398
samtools faidx topolish.unfixed.chr20.fa 20:373977-25698557 > chr20_seq1.fa
samtools faidx topolish.unfixed.chr20.fa 20:1-373976 > chr20_seq2.fa
samtools faidx topolish.unfixed.chr20.fa 20:25803664-71933398 > chr20_seq3.fa

sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i chr20_order.list.tab -o topolish.fixed.chr20.revmap.fa -p 100"
sbatch --dependency=afterok:658059 process_and_qv_fasta.sh topolish.fixed.chr20.revmap.fa

# Chr23
samtools faidx ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa 23 > topolish.unfixed.chr23.fa
sbatch run_rcmap_only.sh topolish.unfixed.chr23.fa
# Bob lists the middle portion as erroneous, but it's confirmed by the recmap as well
# Segments: 23:30762598-31126683 -, 23:31126682-52298066 -, 23:1-307625597 -
samtools faidx topolish.unfixed.chr23.fa 23:30762598-31126683 > chr23_seq1.fa
samtools faidx topolish.unfixed.chr23.fa 23:31126682-52298066 > chr23_seq2.fa
samtools faidx topolish.unfixed.chr23.fa 23:1-30762597 > chr23_seq3.fa

sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i chr23_order.list.tab -o topolish.fixed.chr23.revmap.fa -p 100"
sbatch --dependency=afterok:658062 process_and_qv_fasta.sh topolish.fixed.chr23.revmap.fa

# ChrX
# Bob found a few RH markers that are not supposed to be on X. I'll try to fix them
samtools faidx ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa X > topolish.unfixed.chrX.fa
sbatch run_rcmap_only.sh topolish.unfixed.chrX.fa
# Actually, Bob says that the X is likely ok. We'll leave it for now.

# Reorienting fastas
# I just need to invert the following chrs:
samtools faidx ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa 7 > topolish.unfixed.chr7.fa
samtools faidx ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa 9 > topolish.unfixed.chr9.fa
samtools faidx ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa 18 > topolish.unfixed.chr18.fa
samtools faidx ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa 21 > topolish.unfixed.chr21.fa
samtools faidx ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa 24 > topolish.unfixed.chr24.fa

for i in chr7 chr9 chr18 chr21 chr24; do sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i ${i}_order_list.tab -o topolish.fixed.${i}.revmap.fa"; done

# Finally, gluing together all of the pieces
ls topolish.fixed.chr*.fa > correction_fastas.list
vim correction_fastas.list # Final edits of fastas that I want to incorporate
sbatch ../chr_fixing/reorder_fasta.pl ARS-UCD1.0.3.fa ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fixed.nosplit.fa correction_fastas.list
sbatch process_and_qv_fasta.sh ARS-UCD1.0.3.fa
```


#### process_and_qv_fasta.sh

```bash
#!/usr/bin/bash
#SBATCH --nodes=1
#SBATCH --mem=10000
#SBATCH --ntasks-per-node=2
# $1 = input fasta file

module load samtools
module load bwa
module load java/jdk1.8.0_92

alignrcscript=/mnt/nfs/nfs2/dbickhart/dominette_asm/recombination/alignAndOrderSnpProbes.pl
alignrcmanifest=/mnt/nfs/nfs2/dbickhart/dominette_asm/recombination/rcmap_manifest.fa
gapfastagen=/mnt/nfs/nfs2/bickhart-users/binaries/GetMaskBedFasta/store/GetMaskBedFasta.jar

gapbed=${1}.gap.bed
gapstats=${1}.gap.stats
rcmap=${1}.rcmap

samtools faidx $1
bwa index $1
perl $alignrcscript -a $1 -p $alignrcmanifest -o $rcmap
java -Xmx10g -jar $gapfastagen -f $1 -o $gapbed -s $gapstats
```

#### alignAndOrderSnpProbes.pl

```perl
#!/usr/bin/perl
#SBATCH --nodes=1
#SBATCH --mem=10000
#SBATCH --ntasks-per-node=1
# This is a one-shot script designed to map and order SNP probes from the recombination map to a new assembly
# Output: base.tab <- snpnames and mapping coordinates
# Output: base.segs <- identified chromosome segments
# Output: base.conflicts <- conflicting segments
# Output: base.stats <- general statistics

use strict;
use Getopt::Std;

my $usage = "perl $0 (-a <assembly fasta> -p <probe fasta>) || (-n <nucmer aligns>) -o <output file basename>\n";
my %opts;
getopt('apon', \%opts);

unless(((defined($opts{'a'}) && defined($opts{'p'})) || defined($opts{'n'})) && defined($opts{'o'})){
        print $usage;
        exit;
}

my $unmaps = 0; my $maps = 0;
my %aligns; # {ochr}->{opos} = [probe, chr, pos, orient]

if(defined($opts{'a'})){
open(my $IN, "module load bwa; bwa mem $opts{a} $opts{p} |") || die "Could not begin BWA alignments!\n";
while(my $line = <$IN>){
        if($line =~ /^@/){
                next;
        }

        chomp $line;
        my @segs = split(/\t/, $line);
        my @rnsegs = split(/\./, $segs[0]);
        if($segs[1] & 2048){
                next;
        }
        if($rnsegs[1] == 0){next;} # Takes care of probes without prior chromosome alignments
        if($segs[2] eq "*"){
                $unmaps++; # Count unmapped probes
        }else{
                $maps++;
        }
        my $orient = ($segs[1] & 16)? "-" : "+";
        $aligns{$rnsegs[1]}->{$rnsegs[2]} = [$rnsegs[0], $segs[2], $segs[3], $orient];
}
close $IN;
}elsif(defined($opts{'n'})){
        open(my $IN, "< $opts{n}") || die "Could not open nucmer aligns!\n";
        while(my $line = <$IN>){
                chomp $line;
                my @segs = split(/\t/, $line);
                $maps++;
                my $orient = ($segs[2] > $segs[3])? "-" : "+";
                $aligns{$segs[11]}->{$segs[0]} = ["none", $segs[12], $segs[2], $orient];
        }
        close $IN;
}

open(my $OUT, "> $opts{o}.tab");
open(my $STATS, "> $opts{o}.stats");
open(my $SEGS, "> $opts{o}.segs");
print {$STATS} "Mapping probes: $maps\tUnmapped probes: $unmaps\n";
foreach my $chr (sort{$a <=> $b} keys(%aligns)){
        my ($consensus, $values) = determineConsensus($aligns{$chr});
        print {$STATS} "Ref $chr consensus:";
        for (my $x = 0; $x < scalar(@{$consensus}); $x++){
                print {$STATS} " $consensus->[$x]:$values->[$x]";
        }
        print {$STATS} "\n";

        my ($refblocks, $qblocks) = identifyAndCondenseSegs($aligns{$chr}, $consensus->[0]);
        for(my $x = 0; $x < scalar(@{$refblocks}); $x++){
                my $ref = $refblocks->[$x];
                my $query = $qblocks->[$x];
                my $rlen = abs($ref->[1] - $ref->[0]);
                my $qlen = abs($query->[0] - $query->[1]);
                my $orient = ($query->[0] < $query->[1])? "+" : "-";
                print {$SEGS} "$chr\t$ref->[0]\t$ref->[1]\t$query->[2]\t$query->[0]\t$query->[1]\t$orient\t$rlen\t$qlen\n";
        }

        foreach my $pos (sort{$a <=> $b} keys(%{$aligns{$chr}})){
                my $arrayref = $aligns{$chr}->{$pos};
                print {$OUT} join("\t", @{$arrayref});
                print {$OUT} "\t$chr\t$pos\n";
        }
}
close $OUT;

exit;

sub identifyAndCondenseSegs{
        my ($hashref, $consensus) = @_;
        # Logic: tolerate one deviation in consensus, otherwise condense region into a block
        my @refblock; # [start, end]
        my @queryblock; # [start, end, chr, testbit]

        my @buff; my $count = 0; my $segs = 0; my $skip = 0;
        foreach my $pos (sort{$a <=> $b} keys(%{$hashref})){
                my $query = $hashref->{$pos};
                if($query->[1] eq "*"){next;} # skip unmapped segs
                push(@buff, [$pos, $query]);
                if($count < 2){
                        $count++;
                        # Fill the initial container buffer
                        next;
                }

                if(scalar(@refblock) - 1 < $segs){
                        # starting a new segment
                        push(@refblock, [$buff[0]->[0], $buff[0]->[0]]);
                        push(@queryblock, [$buff[0]->[1]->[2], $buff[0]->[1]->[2], $buff[0]->[1]->[1]]);
                }

                # Test two consecutive probes in the middle of the window to see if they match expectations
                my $comparator = $buff[0]->[1];
                my $test1 = $buff[1]->[1];
                my $test2 = $buff[2]->[1];
                # avg pairwise distance between reference probes in this view
                my $refDist = (($buff[1]->[0] - $buff[0]->[0]) + ($buff[2]->[0] - $buff[1]->[0])) / 2;
                my $t1dist = abs($test1->[2] - $comparator->[2]);
                my $t2dist = abs($test2->[2] - $comparator->[2]);

                if($skip){
                        $skip = 0;
                }else{
                        # passed the test bit for singleton deviations in consensus
                        if(($t1dist > 5 * $refDist && $t2dist > 5 * $refDist) ||
                                ($test1->[1] ne $consensus && $test2->[1] ne $consensus)){
                                $segs++; # The conditional now knows to start a new segment
                        }elsif($t1dist > 5 * $refDist || $test1->[1] ne $consensus){
                                # We don't want singletons to screw up our segments
                                $skip = 1;
                        }
                        # Update the current segments
                        $refblock[-1]->[1] = $buff[0]->[0];
                        $queryblock[-1]->[1] = $buff[0]->[1]->[2];
                }

                shift(@buff); # Remove the preceeding buffer item
        }
        if(scalar(@buff) < 3 && scalar(@refblock) < 1){
                # For alignments with fewer lines than chromosomes
                push(@refblock, [$buff[0]->[0], $buff[0]->[0]]);
                push(@queryblock, [$buff[0]->[1]->[2], $buff[0]->[1]->[2], $buff[0]->[1]->[1]]);
                if(scalar(@buff) > 1){
                        if($buff[1]->[1]->[2] eq $consensus){
                                $refblock[0]->[1] = $buff[1]->[0];
                                $queryblock[0]->[1] = $buff[1]->[1]->[2];
                        }else{
                                push(@refblock, [$buff[1]->[0], $buff[1]->[0]]);
                                push(@queryblock, [$buff[1]->[1]->[2], $buff[1]->[1]->[2], $buff[1]->[1]->[1]]);
                        }
                }
        }else{
        # Update the final segments for this chr
        $refblock[-1]->[1] = $buff[-1]->[0];
        $queryblock[-1]->[1] = $buff[-1]->[1]->[2];
        }

        return \@refblock, \@queryblock;
}



sub determineConsensus{
        my ($hashref) = @_;
        # The input is all of the mapped probes from a reference chr
        # All we need to do is to determine the highest mapping percentile chr from the mapping chr
        my %chrs;
        foreach my $pos (keys(%{$hashref})){
                $chrs{$hashref->{$pos}->[1]} += 1;
        }
        my @consensus = sort{$chrs{$b} <=> $chrs{$a}} keys(%chrs);
        my @values = map{$chrs{$_}} @consensus;
        return \@consensus, \@values;
}
```

## ARS-UCD1.0.4 creation

Using Bob's guidelines and a few more problem regions identified from my scan of the rcmap.

> fry:/mnt/nfs/nfs2/dbickhart/dominette_asm/chr_fixing/ver_4_corrections

```bash
# Let's grep out all of the chromosomes I need
samtools faidx ../ARS-UCD1.0.3.fa 21 > ver_3_21.fa
samtools faidx ../ARS-UCD1.0.3.fa 27 > ver_3_27.fa
samtools faidx ../ARS-UCD1.0.3.fa 2 > ver_3_2.fa
samtools faidx ../ARS-UCD1.0.3.fa 10 > ver_3_10.fa
samtools faidx ../ARS-UCD1.0.3.fa 9 > ver_3_9.fa
for i in `ls *.fa`; do echo $i; samtools faidx $i; done

# chr21
# Region: 21:33382423-34381237  
# Should be inverted and placed further up the chromosome.
# RCmap positions and canu contig confirmed
# chr21: Segments: 21:1-33382000: +, , 21:34471679-60613291: +, 21:33382423-34381237: -, 21:60613291-71144717
samtools faidx ver_3_21.fa 21:1-33382000 > chr21_seg1.fa
samtools faidx ver_3_21.fa 21:34471679-60613291 > chr21_seg2.fa
samtools faidx ver_3_21.fa 21:33382423-34381237 > chr21_seg3.fa
samtools faidx ver_3_21.fa 21:60613291-71144717 > chr21_seg4.fa
sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i chr21_order.list.tab -o version_4_fixed_chr21.fa -p 100"

# chr27
# Segment belongs on chr27
# ARS-BFGL-NGS-91530      21      34418807        +       27      36664
# Segments: 21:34386001-34435280:+ to chr27, beginning of chromosome
# considering confirmed as it fits in with another inversion discovered by the rcmap
# chr27: 21:34386001-34435280:+ 27:1-end:+
samtools faidx ver_3_21.fa 21:34386001-34435280 > chr27_seg1.fa 
sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i chr27_order.list.tab -o version_4_fixed_chr27.fa -p 100"

# chr2
# ARS-BFGL-NGS-52539      2       121810158       +       10      18743955
# Here's the area on chr2
#ARS-BFGL-NGS-28919      2       121315884       -       2       122146355
#ARS-BFGL-NGS-40444      2       121967868       -       2       122409628
# Our chr difference: 600kb, UMD3: 300kb. Difficult to break
# Trusting in Bob's dbsnp mappings here
# chr2: chr2:1-121673581: + chr2:121843925-end
samtools faidx ver_3_2.fa 2:1-121673581 > chr2_seg1.fa
samtools faidx ver_3_2.fa 2:121843925-136330933 > chr2_seg2.fa
sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i chr2_order.list.tab -o version_4_fixed_chr2.fa -p 100"

# chr10
# segments:
# chr10: 10:1-18651720:+, 2:121708673-121823734:+, 10:18853496-end
samtools faidx ver_3_10.fa 10:1-18651720 > chr10_seg1.fa
samtools faidx ver_3_2.fa 2:121708673-121823734 > chr10_seg2.fa
samtools faidx ver_3_10.fa 10:18853496-103693712 > chr10_seg3.fa
sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i chr10_order.list.tab -o version_4_fixed_chr10.fa -p 100"

# chr9
# I have no X markers and no other linkage information. My plan is just to remove the region and place it as a "special"
# leftover contig
# segments:
# chr9: 9:1-104017834:+ 9:112550012-end:+, 9:104017834-112550012 to contig_x_unplaced.
samtools faidx ver_3_9.fa 9:1-104017834 >chr9_seg1.fa
samtools faidx ver_3_9.fa 9:112550012-113852591 > chr9_seg2.fa
samtools faidx ver_3_9.fa 9:104017834-112550012 > extra_9_contig.fa
sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i chr9_order.list.tab -o version_4_fixed_chr9.fa -p 100"

# Now stitching together most of the autosomes
sbatch ../reorder_fasta.pl ARS_UCDpreV4.fa ../ARS-UCD1.0.3.fa correction_fastas.v4.list
# Adding the unplaced X chromosome contig
cat ARS_UCDpreV4.fa extra_9_contig.fa > ../ARS-UCD1.0.4.fa
sbatch --nodes=1 --mem=1000 --ntasks-per-node=1 --wrap="samtools faidx ARS-UCD1.0.4.fa; gzip ARS-UCD1.0.4.fa;"
```

Summary: made corrections to 5 chromosomes from ARS-UCD1.0.3.fa. 

* chr2: removed 2:121708673-121823734 and added it to the middle of chr10
* chr21: 
	* removed 21:33382423-34381237 and moved it to the beginning of chr27
	* inverted and moved 21:33382423-34381237 further down the chromosome
* chr9: removed 9:104017834-112550012 and placed it in "contig_x_unplaced"
* chr10: see above
* chr27: see above


## ARS-UCD1.0.5 creation

A bunch of remaining issues to address and some leftover scaffolds to place.

> fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/chr_fixing/ver_5_corrections

```bash
# Leftovers
# Intersecting the rough coordinates of the Leftover contig insertions with gaps
# This is the easiest way to incorporate them into the ASM without causing more headaches!
intersectBed -a leftover_regions.1.0.3.bed -b ARS-UCD1.0.3.fa.gap.bed
19      43249193        43249217        Leftover_ScbfJmS_1654

# Chr6
# There are errors on the beginning and end of the chromosome
# Also, there is a missing portion near the beginning, from UMD_6:1471923-3780334
# The chr6 situation is pretty complex actually:
# End of the chr:
	BTA-77952-no-rs *       0       +       6       119396306
	Hapmap46942-BTA-114876  6       102019559       +       6       126619789
	BTB-01782372    6       102377773       +       6       126981782
	BTB-01534933    6       102824316       -       6       127576198
	Hapmap44179-BTA-102481  6       102876193       -       6       127720898
	BTB-01544044    6       102898160       +       6       127742938
	Hapmap43685-BTA-77920   6       103146861       +       6       128026956
	BTA-09585-no-rs 6       103246085       -       6       128135281
	Hapmap55617-rs29025460  6       103672694       +       6       128567814
	Hapmap53146-ss46526085  6       104115364       +       6       129056666
	BTB-00284077    6       104254666       +       6       129209793
	BTB-00283603    6       104773093       -       6       129719477
# Supposed breakpoint:
	ARS-BFGL-NGS-83571      6       101891483       +       6       106495683
	ARS-BFGL-NGS-111057     6       101912902       -       6       106517122
	ARS-BFGL-NGS-1012       6       101946553       +       6       106546711
	BovineHD0600029934      6       101951972       +       6       106552130
	ARS-BFGL-NGS-79719      6       101978733       +       6       106578932
	BovineHD0600029951      6       102007520       -       6       106607689
	ARS-BFGL-NGS-112900     6       102046963       -       6       106647592
	BovineHD0600029975      6       102102018       +       6       106703398
	ARS-BFGL-NGS-112084     6       102157017       +       6       106758901
	BovineHD0600030003      6       102184676       -       6       106786536
	ARS-BFGL-NGS-28350      6       102206464       +       6       106808225

# Based on Bob's linkage map, The early-102 fragments appear to be a separate block
# Let's be conservative and link only the regions that have consensus recmap and linkage map positioning
# Segments:
# 6:1643535-2914396 :+, 6:1-1354912 +, 6:3125221-101848529 +, 6:104959826-114187345 +, 6:102019559-104831017 +
samtools faidx ../ARS-UCD1.0.4.fa 6:1643535-2914396 > chr6_seg1.fa
samtools faidx ../ARS-UCD1.0.4.fa 6:1-1354912 > chr6_seg2.fa
samtools faidx ../ARS-UCD1.0.4.fa 6:3125221-101848529 > chr6_seg3.fa
samtools faidx ../ARS-UCD1.0.4.fa 6:104959826-114187345 > chr6_seg4.fa
samtools faidx ../ARS-UCD1.0.4.fa 6:102019559-104831017 > chr6_seg5.fa

# Chr7
# This is based on coordinates from ARS-UCD1.0.3, so I need to replicate results here
# Chr7 is an easy fix because it was not modified in 1.0.3
# Bob's linkage map and the recmap are a bit fuzzy as to the placement of the chr10 segment. I will be a bit 
# conservative here as well
# segments:
# 7:1-109601269 +, 7:109766892-109870666 +, 10:93631977-94139219 +
# I saved the last "chunk" of chr7 instead of discarding it
samtools faidx ../ARS-UCD1.0.3.fa 7:1-109601269 > chr7_seg1.fa
samtools faidx ../ARS-UCD1.0.3.fa 7:109766892-109870666 > chr7_seg2.fa
samtools faidx ../ARS-UCD1.0.3.fa 10:93631977-94139219 > chr7_seg3.fa

# Chr10
# I need to redo the ARS-UCD v3 recipe for this chromosome
# ARS_UCD-1.0.3 coords!!
# segments:
# chr10: 10:1-18853496 +, 2:121708673-121823734:+, 10:18853496-93553629, 10:94259680-103693712:+
samtools faidx ../ARS-UCD1.0.3.fa 10:1-18853496 > chr10_seg1.fa
samtools faidx ../ARS-UCD1.0.3.fa 2:121708673-121823734 > chr10_seg2.fa
samtools faidx ../ARS-UCD1.0.3.fa 10:18853496-93553629 > chr10_seg3.fa
samtools faidx ../ARS-UCD1.0.3.fa 10:94259680-103693712 > chr10_seg4.fa

# Chr26
# There is a chunk that needs to be moved to around the 38 mb region.
# 26:2664716-3081519 + belongs between 26:24034259 and 26:24055998 according to the recmap
# But there is also evidence that it belongs somewhere between 50734383 and 50756585 from a probe on the recmap and most of the linkage map
# I'll go with the linkage map here and hope for the best
# segments:
# 26:1-2628677 +, 26:3172062-50734383 +, 26:2664716-3081519 +, 26:50756585-51553036 +
samtools faidx ../ARS-UCD1.0.4.fa 26:1-2628677 > chr26_seg1.fa
samtools faidx ../ARS-UCD1.0.4.fa 26:3172062-50734383 > chr26_seg2.fa
samtools faidx ../ARS-UCD1.0.4.fa 26:2664716-3081519 > chr26_seg3.fa
samtools faidx ../ARS-UCD1.0.4.fa 26:50756585-51553036 > chr26_seg4.fa

# Chr19
# This is a new addition
# Lack of information may mean that the orientation is wrong on my insertion -- we'll have to live with it!
# Segments:
# 19:1-43249193 +, Leftover_ScbfJmS_1654 +, 19:43249217-63373019 +
samtools faidx ../ARS-UCD1.0.4.fa 19:1-43249193 > chr19_seg1.fa
samtools faidx ../ARS-UCD1.0.4.fa Leftover_ScbfJmS_1654 > chr19_seg2.fa
samtools faidx ../ARS-UCD1.0.4.fa 19:43249217-63373019 > chr19_seg3.fa

# Generating order files
perl -e '@fs = `ls *.fa`; foreach $f (@fs){print $f; chomp $f; ($c) = $f =~ /(chr.+)_seg.+.fa/; open($OUT, ">> $c.order.list"); print {$OUT} "$f\t+\n"; close $OUT;}'
# Submitting revision fasta entries
for i in `ls *order.list`; do chr=`echo $i | cut -d'.' -f1`; echo $chr; sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i $i -o version_5_fixed_${chr}.fa -p 100"; done

ls version_*.fa > correction_fastas.v5.list
# I added Leftover_ScbfJmS_1654 to a removal list so that it isn't duplicated in the v5 assembly
sbatch ../reorder_fasta.pl ../ARS-UCD1.0.5.fa ../ARS-UCD1.0.4.fa correction_fastas.v5.list

# So, this should be the 1.0.4 changes as well as the updated chromosomes above
```

Summary: made changes to 5 chromosomes using a combination of v3 and v4 fasta information

* chr10: section from chr2 is placed properly, removed the portion that is the telomere for chr7
* chr7: added the telomeric portion from chr10 to the end of this chr. Also, resectioned portions of the sub-telomeric region
* chr6: fixed a translocation in the beginning of the chr and shuffled the end to match the recmap coordinates
* chr26: moved the misplaced chunk from the 24 Mb to the subtelomeric region. Recmap coordinates were mixed on the placement of this section -- trusted the linkage map here
* chr19: placed Leftover_ScbfJmS_1654 into a gap region near the 43 Mb

## ARS-UCD1.0.6 creation

There are still some remaining issues with chr26 that need to be addressed. I will do my best to catalogue and fix them.

```bash
mkdir ver_6_corrections
cd ver_6_corrections
# chr26
# 26:50191200-50579551  between 23490975 and 23512714
# 26:15016528-15315313:- between 25749185 and 25818753
# 26:15349938-15465426:- between 50050681 and 50119386
# segments:
# 26:1-15016528:+, 26:15465426-23490975:+, 26:50191200-50579551:+, 26:23512714-25749185:+, 26:15016528-15315313:-, 26:25818753-50050681:+, 26:15349938-15465426:-, 26:50050681-50119386:+, 26:50953848-51404555:-, 26:50119386-50856968:+
samtools faidx ../ARS-UCD1.0.5.fa 26:1-15016528 > chr26_seg1.fa
samtools faidx ../ARS-UCD1.0.5.fa 26:15465426-23490975 > chr26_seg2.fa
samtools faidx ../ARS-UCD1.0.5.fa 26:50191200-50579551 > chr26_seg3.fa
samtools faidx ../ARS-UCD1.0.5.fa 26:23512714-25749185 > chr26_seg4.fa
samtools faidx ../ARS-UCD1.0.5.fa 26:15016528-15315313 > chr26_seg5.fa
samtools faidx ../ARS-UCD1.0.5.fa 26:25818753-50050681 > chr26_seg6.fa
samtools faidx ../ARS-UCD1.0.5.fa 26:15349938-15465426 > chr26_seg7.fa
samtools faidx ../ARS-UCD1.0.5.fa 26:50050681-50119386 > chr26_seg8.fa
samtools faidx ../ARS-UCD1.0.5.fa 26:50953848-51404555 > chr26_seg9.fa
samtools faidx ../ARS-UCD1.0.5.fa 26:50119386-50856968 > chr26_seg10.fa

# chr5
# There's one inversion remaining
# segments:
# 5:1-79055811:+, 5:79055811-79460974:-, 5:79460974-120000469
samtools faidx ../ARS-UCD1.0.5.fa 5:1-79055811 > chr5_seg1.fa
samtools faidx ../ARS-UCD1.0.5.fa 5:79055811-79460974 > chr5_seg2.fa
samtools faidx ../ARS-UCD1.0.5.fa 5:79460974-120000469 > chr5_seg3.fa

# chr8
# There's one inversion remaining
# segments:
# 8:1-87651142:+, 8:87651142-87861659:-, 8:87861659-113220712:+
samtools faidx ../ARS-UCD1.0.5.fa 8:1-87651142 > chr8_seg1.fa
samtools faidx ../ARS-UCD1.0.5.fa 8:87651142-87861659 > chr8_seg2.fa
samtools faidx ../ARS-UCD1.0.5.fa 8:87861659-113220712 > chr8_seg3.fa

# chr18
# There's one inversion remaining
# segments:
# 18:1-62366442:+, 18:62366442-62533251:-, 18:62533251-65953167:+
samtools faidx ../ARS-UCD1.0.5.fa 18:1-62366442 > chr18_seg1.fa
samtools faidx ../ARS-UCD1.0.5.fa 18:62366442-62533251 > chr18_seg2.fa
samtools faidx ../ARS-UCD1.0.5.fa 18:62533251-65953167 > chr18_seg3.fa

# Now to generate the intermediary order files
perl -e '@fs = `ls *.fa`; foreach $f (@fs){print $f; chomp $f; ($c) = $f =~ /(chr.+)_seg.+.fa/; open($OUT, ">> $c.order.list"); print {$OUT} "$f\t+\n"; close $OUT;}'
# Submitting version 6 corrections
for i in `ls *order.list`; do chr=`echo $i | cut -d'.' -f1`; echo $chr; sbatch --nodes=1 --mem=50000 --ntasks-per-node=4 --wrap="module load java/jdk1.8.0_92; java -Xmx49g -jar /mnt/nfs/nfs2/bickhart-users/binaries/CombineFasta/store/CombineFasta.jar order -i $i -o version_6_fixed_${chr}.fa -p 100"; done

# Wrapping it all together
ls version_6_fixed_chr*.fa > correction_fastas.v6.list
sbatch ../reorder_fasta.pl ../ARS-UCD1.0.6.fa ../ARS-UCD1.0.5.fa correction_fastas.v6.list

sbatch --dependency=afterok:658590 --nodes=1 --mem=4000 --ntasks-per-node=1 --wrap="samtools faidx ARS-UCD1.0.6.fa; gzip ARS-UCD1.0.6.fa;"
```

<a name="snps"></a>
## SNP remapping and stats

These are my notes on the remapping of SNP probes from the HD array to the new assembly. I have two main goals here:

* Generate a SNP location list for Paul and John to check
* Determine how many SNP locations have moved from UMD3

> 3850: /home/bickhart
```bash
perl -e 'for($x = 0; $x < 6; $x++){<>;} while(<>){chomp; if($_ =~ /^#/){next;} @s = split(/,/); @b = split(/[\[\]]/, $s[6]); $b[2] =~ tr/ACGT/TGCA/; $b[2] = reverse($b[2]); print ">$s[1].f\n$b[0]\n>$s[1].r\n$b[2]\n";} close IN;' < /work1/grw/chips/GH2/GGP_HDv2_B_StrandReport_FDT_V1.csv > ggp_probe_design.fa

perl -e 'open(O1, "> ggp_probe_design.1.fa"); open(O2, "> ggp_probe_design.2.fa"); while($n1 = <>){ $s1 = <>; $n2 = <>; $s2 = <>; $n1 =~ s/.f//; $n2 =~ s/.r//; print O1 "$n1$s1"; print O2 "$n2$s2"; }' < ggp_probe_design.fa
```

> pwd: /home/dbickhart/share/btau4_data

```bash
# I converted the BovineHD data into single line fasta entries.
```



