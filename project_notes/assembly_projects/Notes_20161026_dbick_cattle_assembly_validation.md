# Cattle genome assembly and validation
---
*10/26/2016*

## Table of Contents
* [Sequence alignment and summary statistics](#stats)
* [Polished assembly](#polish)
* [SNP remapping and stats](#snps)

<a name="stats"></a>
## Sequence alignment and summary statistics

I need to align the data to the following cattle assemblies: 

* The UMD3 assembly
* The Btau4 assembly
* The PacBio contigs (the march Cattle assembly)
* The finished assembly (to be generated by Aleksey)

Let's start aligning to the assemblies I have right now. I'm also going to generate the spreadsheet with the information.

> Blade14: /mnt/nfs/nfs2/dbickhart/dominette_asm

```bash
ls /mnt/nfs/nfs2/SequenceData/Dominette/Dominette_NextSeq_data/*/*.fastq.gz | perl -MFile::Basename -e '%data; while(<>){chomp; $orig = $_; $bname = basename($_); @entries = split(/\//, $orig); @bentries = split(/_/, $bname); $data{"$entries[-2]_$bentries[2]"}->{$bentries[3]} = $orig;} foreach my $k (keys(%data)){print $data{$k}->{"R1"} . "\t" . $data{$k}->{"R2"} . "\tdominette\tdominette\n";}' > dominette_nextseq_file_list.tab

# UMD3
perl ~/perl_toolchain/sequence_data_pipeline/runMergedBamPipeline.pl --fastqs dominette_nextseq_file_list.tab --output umd3 --reference ../../Genomes/Bos_taurus.UMD3.1.73.fa --config ./quick_pipeline.cnfg --threads 4

```

Serge's pipeline only works with SGE. I need to hijack some of his commands to run Lumpy and the other tools without using his full pipeline.

```bash
# Preparing discordant and split read bam files
samtools view -b -F 1294 btau4/dominette_merged_btau4.bam > btau4/dominette_merged_btau4.discordants.bam
samtools view -h btau4/dominette_merged_btau4.bam \
          | ~/lumpy-sv/scripts/extractSplitReads_BwaMem -i stdin \
          | samtools view -Sb - \
          > btau4/dominette_merged_btau4.splitters.bam

samtools index btau4/dominette_merged_btau4.discordants.bam
samtools index btau4/dominette_merged_btau4.splitters.bam

# Lumpy analysis
pars=`samtools view btau4/dominette_merged_btau4.bam | head -n100000 | ~/lumpy-sv/scripts/pairend_distro.py -r 150 -X 4 -N 10000 -o btau4/dominette_merged_btau4.histo`
mean=`echo $pars | grep 'mean' | awk '{print $1}' |sed s/mean://g`
sd=`echo $pars |grep 'mean' | awk '{print $NF}' |sed s/stdev://g`
MIN=`echo "$mean $sd" |awk '{printf("%d\n", $1-3*$2)}' |awk '{if ($1 < 0) print 0}'`
MAX=`echo "$mean $sd" |awk '{printf("%d\n", $1+3*$2)}'`

PE=""
SR=""

PE="$PE -pe id:sample,bam_file:btau4/dominette_merged_btau4.discordants.bam,histo_file:btau4/dominette_merged_btau4.histo,mean:$mean,stdev:$sd,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20"
SR="$SR -sr id:sample,bam_file:btau4/dominette_merged_btau4.splitters.bam,back_distance:10,min_mapping_threshold:20,weight:1,min_clip:20"
lumpy -mw 4 -tt 0 $PE $SR > btau4/dominette_merged_btau4.lumpy.vcf

# FRC bam
PE=""
PE="$PE --pe-sam btau4/dominette_merged_btau4.bam --pe-max-insert $MAX"
FRC $PE --genome-size $GS --output btau4/dominette_merged_btau4

# Freebayes
$FREEBAYES -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 1 -F 0.5 -b btau4/dominette_merged_btau4.bam -v btau4/dominette_merged_btau4.bayes.vcf -f $ASM

# QV estimate
NUM_SNP=`cat btau4/dominette_merged_btau4.bayes.vcf |grep -v "#" | awk -F "\t" '{print $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$8}' | tr ';' ' ' | sed s/AB=//g | awk -v WEIGHT=$WEIGHT '{if ($6 > WEIGHT) print $0}' | awk -v SUM=0 '{if (length($4) == length($5)) { SUM+=length($4); } else if (length($4) < length($5)) { SUM+=length($5)-length($4); } else { SUM+=length($4)-length($5)}} END { print SUM}'`

NUM_BP=`samtools depth btau4/dominette_merged_btau4.bam |awk '{if ($NF >= 3) SUM++; } END { print SUM}'`
QV=`echo "$NUM_SNP $NUM_BP" | awk '{print (-10*log($1/$2)/log(10))}'`
echo $QV > btau4/dominette_merged_btau4.qv
```

I consolidated the above code into a shell script that can run on each merged bam file in sequence.

```bash
sh serge_script_oneshot.sh btau4/dominette_merged_btau4 /mnt/iscsi/vnx_gliu_7/reference/bosTau4.fa.gz

sh serge_script_oneshot.sh umd3/dominette.merged.umd3 /mnt/iscsi/vnx_gliu_7/reference/umd3_kary_unmask_ngap.fa

sh serge_script_oneshot.sh canu/canu.dominette.topolish canu/topolish.filledWithCanuAndPBJelly.fasta
```

I am also queuing up the new assembly (pre pilon).

```bash
bwa index canu/topolish.filledWithCanuAndPBJelly.fasta.gz ; samtools faidx canu/topolish.filledWithCanuAndPBJelly.fasta.gz ; perl ~/perl_toolchain/sequence_data_pipeline/runMergedBamPipeline.pl --fastqs dominette_nextseq_file_list.tab --output canu --reference canu/topolish.filledWithCanuAndPBJelly.fasta.gz --config ./quick_pipeline.cnfg --threads 4
```

OK, the shell script had a few problems. For starters, freebayes can't handle gzipped fastas. Rerunning the last steps of the pipeline.

```bash
# btau4
samtools depth dominette_merged_btau4.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
	2697640645
freebayes -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 2 -F 0.5 -b dominette_merged_btau4.bam -v dominette_merged_btau4.bayes.vcf -f /mnt/iscsi/vnx_gliu_7/reference/bosTau4.fa
perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < dominette_merged_btau4.bayes.vcf
	281999

perl -e '$ns = 281999; $nb = 2697640645; print (-10 * log($ns/$nb)/log(10)); print "\n";'
	39.8073652818702 # Btau4 qv

perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f dominette_merged_btau4_Features.txt -c 1
Entry   Count
COMPR_PE        6407
HIGH_COV_PE     4406
HIGH_NORM_COV_PE        3671
HIGH_OUTIE_PE   988
HIGH_SINGLE_PE  3247
HIGH_SPAN_PE    9240
LOW_COV_PE      135529
LOW_NORM_COV_PE 137377
STRECH_PE       16385

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < dominette_merged_btau4.lumpy.vcf | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        12870
DUPLICATION     1305
INTERCHROM      9031
INVERSION       2152

# Errors per 100 mbp = (25358 / 28.0) = 905.64

# umd3
samtools depth dominette.merged.umd3.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
	2633997017
freebayes -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 2 -F 0.5 -b dominette.merged.umd3.bam -v dominette.merged.umd3.bayes.vcf -f ../../../Genomes/Bos_taurus.UMD3.1.73.fa
perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < dominette.merged.umd3.bayes.vcf
	300091

perl -e '$ns = 300091; $nb = 2633997017; print (-10 * log($ns/$nb)/log(10)); print "\n";'
	39.4336230805122 # UMD3 qv

perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f dominette.merged.umd3_Features.txt -c 1
Entry   Count
COMPR_PE        12348
HIGH_COV_PE     7660
HIGH_NORM_COV_PE        7169
HIGH_OUTIE_PE   2303
HIGH_SINGLE_PE  1295
HIGH_SPAN_PE    4135
LOW_COV_PE      64527
LOW_NORM_COV_PE 67417
STRECH_PE       21891

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < dominette.merged.umd3.lumpy.vcf | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        13963
DUPLICATION     2493
INTERCHROM      8711
INVERSION       5470

# Errors per 100 mbp = (30637 / 28.0) = 1094.18


## Computomix
perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f canu/canu.dominette.topolish_Features.txt -c 1
Entry   Count
COMPR_PE        6526
HIGH_COV_PE     7333
HIGH_NORM_COV_PE        5759
HIGH_OUTIE_PE   80
HIGH_SINGLE_PE  118
HIGH_SPAN_PE    5982
LOW_COV_PE      52772
LOW_NORM_COV_PE 50719
STRECH_PE       16752

lumpy -mw 4 -tt 0 -pe id:sample,bam_file:canu.dominette.topolish.discordants.bam,histo_file:canu.dominette.topolish.histo,mean:628.478,stdev:168.47,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 -sr id:sample,bam_file:canu.dominette.topolish.splitters.bam,back_distance:10,min_mapping_threshold:20,weight:1,min_clip:20 > canu.dominette.topolish.lumpy.vcf

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < canu/canu.dominette.topolish.lumpy.vcf  | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        4272
DUPLICATION     320
INTERCHROM      2132
INVERSION       487


```

OK, let's summarize things:

| Feature | Btau4 | UMD3 | Serge | Aleksey |Description |
| :--- | ---: | ---: | ---: | ---: |:--- |
| QV | 39.80 | 39.43 | 32.78 | 38.85 | Phred-based assessment of INDEL and SNP errors in assembly |
| Errors / 100 Mbp | 905.64 | 1094.18 | 257 | 213.75 | Ratio of Lumpy SV calls per 100 Mbp |
| DELETION | 12870 | 13963 | 4272 | 1363 | Lumpy-SV deletions |
| DUPLICATION | 1305 | 2493 | 320 | 611 | Lumpy-SV duplications |
| INTERCHROM | 9031 |  8711 | 2132| 3943 | Lumpy-SV interchromosome regions |
| INVERSION | 2152 |  5470 | 487 | 68 | Lumpy-SV inversions |
|COMPR_PE         |   6407|12348| 6526| 9000 | Areas with low CE statistics |
|HIGH_COV_PE      |   4406|7660| 7333| 10098 | Higher read coverage |
|HIGH_NORM_COV_PE |   3671|7169| 5759 | 7944 | High coverage of normal paired-end reads |
|HIGH_OUTIE_PE    |    988|2303| 80| 79 | Regions with high numbers of misoriented or distant pairs |
|HIGH_SINGLE_PE   |   3247|1295| 118 | 251 |Regions with high numbers of unmapped pairs |
|HIGH_SPAN_PE     |   9240|4135| 5982 | 14180 |Regions with high numbers of disc. pairs that map to different scaffolds |
|LOW_COV_PE       | 135529|64527| 52772 | 100814 |Low read coverage |
|LOW_NORM_COV_PE  | 137377|67417| 50719 | 105271 |Low coverage of normal paired-end reads |
|STRECH_PE        |  16385|21891| 16752 | 15079 |Areas with high CE statistics |

<a name="polished"></a>
## Polished assembly

Now that we have the polished assembly back from Aleksey, it's time to process it.

```bash
module load bwa
module load samtools/1.3-20-gd49c73b

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="bwa index polished.fa"
sbatch --mem=2000 --nodes=1 --ntasks-per-node=1 --wrap="samtools faidx polished.fa"

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="java -Xmx19g -jar /mnt/nfs/nfs2/bickhart-users/binaries/GetMaskBedFasta/store/GetMaskBedFasta.jar -f polished.fa -o polished.gaps.bed -s polished.gaps.stats"
sbatch --nodes=1 --mem=2000 --ntasks-per-node=8 --wrap 'samtools merge -c -p --threads 8 polished.merged.dominette.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L001_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L002_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L003_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L004_001.bam'

sbatch --nodes=1 --ntasks-per-node=1 --mem=1000 --wrap='samtools index bwa-out/polished.merged.dominette.bam'
sbatch serge_script_oneshot.sh polished/bwa-out/polished.merged.dominette polished/polished.fa

# Lumpy failed because of weird scripting errors. Rerunning...
sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; samtools view polished.merged.dominette.bam | tail -n+100000 | /opt/agil_cluster/lumpy-sv-0.2.12-51-g16b6876/bin/../scripts/pairend_distro.py -r 150 -X 4 -N 10000 -o polished.merged.dominette.histo"

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; lumpy -mw 4 -tt 0 -pe id:dominette,bam_file:polished.merged.dominette.bam,histo_file:polished.merged.dominette.histo,mean:626.926292629,stdev:193.453829908,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 > polished.merged.dominette.lumpy.vcf"

./vcfToBedpe -i polished/bwa-out/polished.merged.dominette.lumpy.vcf -o polished/bwa-out/polished.merged.dominette.lumpy.bedpe

perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < polished.merged.dominette.bayes.vcf
353921
samtools depth polished.merged.dominette.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
2720125193
perl -e 'chomp(@ARGV); $ns = $ARGV[0]; $nb = $ARGV[1]; print (-10 * log($ns/$nb)/log(10)); print "\n";' 353921 2720125193
38.8568256039133

# Checking to see if the SNPs and indels correspond to lumpy SV calls
# Pulling lumpy calls into beds and then pulling only the >65% AB percentile variants from the freebayes output
perl -lane 'if($F[0] =~ /^#/){next;} if($F[1] < 0){ $F[1] = 0;} if($F[3] < 0){$F[3] = 0;} if($F[10] eq "BND"){print "$F[0]\t$F[1]\t$F[2]\t$F[10]"; print "$F[3]\t$F[4]\t$F[5]\t$F[10]";}else{print "$F[0]\t$F[1]\t$F[5]\t$F[10]";}' < polished.merged.dominette.lumpy.bedpe > polished.merged.dominette.lumpy.bed
perl -lane 'if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;} $e = $F[1] + 1; print "$F[0]\t$F[1]\t$e";' < polished.merged.dominette.bayes.vcf > polished.merged.dominette.bayes.bed
intersectBed -a polished.merged.dominette.lumpy.bed -b polished.merged.dominette.bayes.bed -c | perl -lane 'if($F[4] > 0){print $_;}' | wc -l
2417   <- total SNPs/INDELs within lumpy predicted discordant regions (~24% of total)
perl -lane 'if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;} $e = $F[1] + 1; print "$F[0]\t$F[1]\t$e";' < polished.merged.dominette.bayes.vcf > polished.merged.dominette.bayes.bed
[dbickhart@vm-agil-251-fry bwa-out]$ intersectBed -a polished.merged.dominette.lumpy.bed -b polished.merged.dominette.bayes.bed -c | perl -lane 'if($F[4] > 0){print $_;}' | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 3 -m
```
### Variants within lumpy sv coordinates in polished assembly
|Entry | Count|
|:-----|-----:|
|BND   |  1436|
|DEL   |   506|
|DUP   |   432|
|INV   |    43|


<a name="ctx"></a>
## Computomix assembly

The polished assembly looks corrupted... I'm going to run a comparison with the real computomix assembly to see how that panned out.

> fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/ctx

```bash
sh create_bwa_batchfiles.sh dominette_nextseq_file_list.tab
sbatch --nodes=1 --ntasks-per-node=2 --mem=10000 --wrap="module load bwa; module load samtools; bwa index CTX3.fasta; samtools faidx CTX3.fasta"

sleep 3h; find batchfiles-bwa/ -name *.sh | xargs -I {} sbatch {}
sbatch --nodes=1 --ntasks-per-node=10 --mem=5000 --wrap="module load samtools/1.3-20-gd49c73b; samtools merge -c -p -@ 9 polishedAsm.NextSeq.dominette.merged.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L001_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L002_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L003_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L004_001.bam; samtools index polishedAsm.NextSeq.dominette.merged.bam;"

sbatch ../serge_script_oneshot.sh bwa-out/polishedAsm.NextSeq.dominette.merged CTX3.fasta dominette
```

## Other assemblies

Aleksey made two additional assemblies that need to be run through the pipeline.

> fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/

```bash
#### Polished.final ####
mkdir polished.final
cd polished.final

sbatch --nodes=1 --mem=6000 --ntasks-per-node=1 --wrap="module load bwa; module load samtools; wget ftp://ftp.genome.umd.edu/pub/dominette/polished.final.fa.gz; gunzip polished.final.fa.gz; bwa index polished.final.fa; samtools faidx polished.final.fa;"

perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b alignments -t ../dominette_nextseq_file_list.tab -f polished.final.fa -m
sbatch serge_script_oneshot.sh polished.final/alignments/dominette/dominette.sorted.merged polished.final/polished.final.fa dominette

#### Topolish no 1b ####
mkdir topolish.no1b
cd topolish.no1b

sbatch --nodes=1 --mem=6000 --ntasks-per-node=1 --wrap="module load bwa; module load samtools; wget ftp://ftp.genome.umd.edu/pub/dominette/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta.gz; gunzip topolish.filledWithCanuAndPBJelly.withX.no1b.fasta.gz; bwa index topolish.filledWithCanuAndPBJelly.withX.no1b.fasta; samtools faidx topolish.filledWithCanuAndPBJelly.withX.no1b.fasta;"

perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b alignments -t ../dominette_nextseq_file_list.tab -f topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -m
sbatch serge_script_oneshot.sh topolish.no1b/alignments/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta dominette

# Damn, I suspect that Slurm automatically kills jobs that post with an ampersand. Going to queue up FRC and lumpy using separate commands
sbatch --nodes=1 --ntasks-per-node=2 --mem=25000 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; lumpy -mw 4 -tt 0  -pe id:dominette,bam_file:topolish.no1b/alignments/dominette/dominette.sorted.merged.discordants.bam,histo_file:topolish.no1b/alignments/dominette/dominette.sorted.merged.histo,mean:626.861177885,stdev:184.997331276,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 > topolish.no1b/alignments/dominette/dominette.sorted.merged.lumpy.2.vcf"
sbatch --nodes=1 --ntasks-per-node=2 --mem=25000 --wrap="module load FRC_align/1.3.0-5b3f53e; FRC  --pe-sam topolish.no1b/alignments/dominette/dominette.sorted.merged.bam --pe-max-insert 1181 --genome-size 2800000000 --output topolish.no1b/alignments/dominette/dominette.sorted.merged.2"

sbatch --nodes=1 --ntasks-per-node=2 --mem=25000 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; lumpy -mw 4 -tt 0  -pe id:dominette,bam_file:polished.final/alignments/dominette/dominette.sorted.merged.discordants.bam,histo_file:polished.final/alignments/dominette/dominette.sorted.merged.histo,mean:666.1878,stdev:182.802370146,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 > polished.final/alignments/dominette/dominette.sorted.merged.lumpy.2.vcf"
```

#### Update of stats table

| Feature | Btau4 | UMD3 | Serge | Aleksey | polished.final | topolish.no1b |Description |
| :--- | ---: | ---: | ---: | ---: | ---: | ---: |:--- |
| QV | 39.80 | 39.43 | 32.78 | 38.85 | 38.23 | 40.87 |Phred-based assessment of INDEL and SNP errors in assembly |
| Errors / 100 Mbp | 905.64 | 1094.18 | 257 | 213.75 | | | Ratio of Lumpy SV calls per 100 Mbp |
| DELETION | 12870 | 13963 | 4272 | 1363 | | | Lumpy-SV deletions |
| DUPLICATION | 1305 | 2493 | 320 | 611 | | | Lumpy-SV duplications |
| INTERCHROM | 9031 |  8711 | 2132| 3943 | | | Lumpy-SV interchromosome regions |
| INVERSION | 2152 |  5470 | 487 | 68 | | | Lumpy-SV inversions |
|COMPR_PE         |   6407|12348| 6526| 9000 | 68847 | 174622 | Areas with low CE statistics |
|HIGH_COV_PE      |   4406|7660| 7333| 10098 | 10320 | 7214 | Higher read coverage |
|HIGH_NORM_COV_PE |   3671|7169| 5759 | 7944 | 8185 | 5481 | High coverage of normal paired-end reads |
|HIGH_OUTIE_PE    |    988|2303| 80| 79 | 133 | 122 | Regions with high numbers of misoriented or distant pairs |
|HIGH_SINGLE_PE   |   3247|1295| 118 | 251 | 306 | 92 | Regions with high numbers of unmapped pairs |
|HIGH_SPAN_PE     |   9240|4135| 5982 | 14180 | 14993 | 5166 | Regions with high numbers of disc. pairs that map to different scaffolds |
|LOW_COV_PE       | 135529|64527| 52772 | 100814 | 107927 | 58672 | Low read coverage |
|LOW_NORM_COV_PE  | 137377|67417| 50719 | 105271 | 111927 | 57701 | Low coverage of normal paired-end reads |
|STRECH_PE        |  16385|21891| 16752 | 15079 | 39885 | 94925 | Areas with high CE statistics |


Now to generate a FRC curve to compare stats.

```R
data.serge <- read.delim("canu/canu.dominette.topolish_FRC.txt", sep=" ", header=FALSE)
data.aleksey <- read.delim("polished/bwa-out/polished.merged.dominette_FRC.txt", sep=" ", header=FALSE)
data.topolish <- read.delim("topolish.no1b/alignments/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
data.final <- read.delim("polished.final/alignments/dominette/dominette.sorted.merged_FRC.txt", sep=" ", header=FALSE)
pdf(file="frc_curve_fourasms.pdf", useDingbats=FALSE)

plot(data.serge$V1, data.serge$V2, type="l", col="red")
lines(data.aleksey$V1, data.aleksey$V2, col="green")
lines(data.topolish$V1, data.topolish$V2, col="blue")
lines(data.final$V1, data.final$V2, col="brown")
legend("topleft", legend = c("Serge", "Aleksey1", "Aleksey2", "topolishNob1"), col = c("red", "green", "blue", "brown"))
dev.off()

pdf(file="frc_curve_threeasms.pdf", useDingbats=FALSE)
plot(data.aleksey$V1, data.aleksey$V2, col="green", type="l")
lines(data.topolish$V1, data.topolish$V2, col="blue")
lines(data.final$V1, data.final$V2, col="brown")
legend("topleft", legend = c("Aleksey1", "Aleksey2", "topolishNoB1"), lty=c(1,1), lwd=c(2,2), col = c("green", "blue", "brown"))

```

Rerunning only on run2 data

```bash
mkdir run2only
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b umd3 -t ../dominett_run2_only_files.tab -f /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b canu -t ../dominett_run2_only_files.tab -f ../canu/topolish.filledWithCanuAndPBJelly.fasta -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b ctx -t ../dominett_run2_only_files.tab -f ../ctx/CTX3.fasta -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b polished -t ../dominett_run2_only_files.tab -f ../polished/polished.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b polished.final -t ../dominett_run2_only_files.tab -f ../polished.final/polished.final.fa -m
perl ~/perl_toolchain/sequence_data_pipeline/generateAlignSlurmScripts.pl -b topolish.no1b -t ../dominett_run2_only_files.tab -f ../topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta -m

sbatch serge_script_oneshot.sh run2only/canu/dominette/dominette.sorted.merged canu/topolish.filledWithCanuAndPBJelly.fasta dominette
sbatch serge_script_oneshot.sh run2only/ctx/dominette/dominette.sorted.merged ctx/CTX3.fasta dominette
sbatch serge_script_oneshot.sh run2only/umd3/dominette/dominette.sorted.merged /mnt/nfs/nfs2/Genomes/umd3_kary_unmask_ngap.fa dominette
sbatch serge_script_oneshot.sh run2only/polished/dominette/dominette.sorted.merged polished/polished.fa dominette
sbatch serge_script_oneshot.sh run2only/polished.final/dominette/dominette.sorted.merged polished.final/polished.final.fa dominette
sbatch serge_script_oneshot.sh run2only/topolish.no1b/dominette/dominette.sorted.merged topolish.no1b/topolish.filledWithCanuAndPBJelly.withX.no1b.fasta dominette
```

Rerunning only on run1 data

```bash

```

<a name="snps"></a>
## SNP remapping and stats

These are my notes on the remapping of SNP probes from the HD array to the new assembly. I have two main goals here:

* Generate a SNP location list for Paul and John to check
* Determine how many SNP locations have moved from UMD3

> 3850: /home/bickhart
```bash
perl -e 'for($x = 0; $x < 6; $x++){<>;} while(<>){chomp; if($_ =~ /^#/){next;} @s = split(/,/); @b = split(/[\[\]]/, $s[6]); $b[2] =~ tr/ACGT/TGCA/; $b[2] = reverse($b[2]); print ">$s[1].f\n$b[0]\n>$s[1].r\n$b[2]\n";} close IN;' < /work1/grw/chips/GH2/GGP_HDv2_B_StrandReport_FDT_V1.csv > ggp_probe_design.fa

perl -e 'open(O1, "> ggp_probe_design.1.fa"); open(O2, "> ggp_probe_design.2.fa"); while($n1 = <>){ $s1 = <>; $n2 = <>; $s2 = <>; $n1 =~ s/.f//; $n2 =~ s/.r//; print O1 "$n1$s1"; print O2 "$n2$s2"; }' < ggp_probe_design.fa
```

> pwd: /home/dbickhart/share/btau4_data

```bash
# I converted the BovineHD data into single line fasta entries.
```



