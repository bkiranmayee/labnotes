# Cattle genome assembly and validation
---
*10/26/2016*

## Table of Contents
* [Sequence alignment and summary statistics](#stats)

<a name="stats"></a>
## Sequence alignment and summary statistics

I need to align the data to the following cattle assemblies: 

* The UMD3 assembly
* The Btau4 assembly
* The PacBio contigs (the march Cattle assembly)
* The finished assembly (to be generated by Aleksey)

Let's start aligning to the assemblies I have right now. I'm also going to generate the spreadsheet with the information.

> Blade14: /mnt/nfs/nfs2/dbickhart/dominette_asm

```bash
ls /mnt/nfs/nfs2/SequenceData/Dominette/Dominette_NextSeq_data/*/*.fastq.gz | perl -MFile::Basename -e '%data; while(<>){chomp; $orig = $_; $bname = basename($_); @entries = split(/\//, $orig); @bentries = split(/_/, $bname); $data{"$entries[-2]_$bentries[2]"}->{$bentries[3]} = $orig;} foreach my $k (keys(%data)){print $data{$k}->{"R1"} . "\t" . $data{$k}->{"R2"} . "\tdominette\tdominette\n";}' > dominette_nextseq_file_list.tab

# UMD3
perl ~/perl_toolchain/sequence_data_pipeline/runMergedBamPipeline.pl --fastqs dominette_nextseq_file_list.tab --output umd3 --reference ../../Genomes/Bos_taurus.UMD3.1.73.fa --config ./quick_pipeline.cnfg --threads 4

```

Serge's pipeline only works with SGE. I need to hijack some of his commands to run Lumpy and the other tools without using his full pipeline.

```bash
# Preparing discordant and split read bam files
samtools view -b -F 1294 btau4/dominette_merged_btau4.bam > btau4/dominette_merged_btau4.discordants.bam
samtools view -h btau4/dominette_merged_btau4.bam \
          | ~/lumpy-sv/scripts/extractSplitReads_BwaMem -i stdin \
          | samtools view -Sb - \
          > btau4/dominette_merged_btau4.splitters.bam

samtools index btau4/dominette_merged_btau4.discordants.bam
samtools index btau4/dominette_merged_btau4.splitters.bam

# Lumpy analysis
pars=`samtools view btau4/dominette_merged_btau4.bam | head -n100000 | ~/lumpy-sv/scripts/pairend_distro.py -r 150 -X 4 -N 10000 -o btau4/dominette_merged_btau4.histo`
mean=`echo $pars | grep 'mean' | awk '{print $1}' |sed s/mean://g`
sd=`echo $pars |grep 'mean' | awk '{print $NF}' |sed s/stdev://g`
MIN=`echo "$mean $sd" |awk '{printf("%d\n", $1-3*$2)}' |awk '{if ($1 < 0) print 0}'`
MAX=`echo "$mean $sd" |awk '{printf("%d\n", $1+3*$2)}'`

PE=""
SR=""

PE="$PE -pe id:sample,bam_file:btau4/dominette_merged_btau4.discordants.bam,histo_file:btau4/dominette_merged_btau4.histo,mean:$mean,stdev:$sd,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20"
SR="$SR -sr id:sample,bam_file:btau4/dominette_merged_btau4.splitters.bam,back_distance:10,min_mapping_threshold:20,weight:1,min_clip:20"
lumpy -mw 4 -tt 0 $PE $SR > btau4/dominette_merged_btau4.lumpy.vcf

# FRC bam
PE=""
PE="$PE --pe-sam btau4/dominette_merged_btau4.bam --pe-max-insert $MAX"
FRC $PE --genome-size $GS --output btau4/dominette_merged_btau4

# Freebayes
$FREEBAYES -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 1 -F 0.5 -b btau4/dominette_merged_btau4.bam -v btau4/dominette_merged_btau4.bayes.vcf -f $ASM

# QV estimate
NUM_SNP=`cat btau4/dominette_merged_btau4.bayes.vcf |grep -v "#" | awk -F "\t" '{print $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$8}' | tr ';' ' ' | sed s/AB=//g | awk -v WEIGHT=$WEIGHT '{if ($6 > WEIGHT) print $0}' | awk -v SUM=0 '{if (length($4) == length($5)) { SUM+=length($4); } else if (length($4) < length($5)) { SUM+=length($5)-length($4); } else { SUM+=length($4)-length($5)}} END { print SUM}'`

NUM_BP=`samtools depth btau4/dominette_merged_btau4.bam |awk '{if ($NF >= 3) SUM++; } END { print SUM}'`
QV=`echo "$NUM_SNP $NUM_BP" | awk '{print (-10*log($1/$2)/log(10))}'`
echo $QV > btau4/dominette_merged_btau4.qv
```

I consolidated the above code into a shell script that can run on each merged bam file in sequence.

```bash
sh serge_script_oneshot.sh btau4/dominette_merged_btau4 /mnt/iscsi/vnx_gliu_7/reference/bosTau4.fa.gz

sh serge_script_oneshot.sh umd3/dominette.merged.umd3 /mnt/iscsi/vnx_gliu_7/reference/umd3_kary_unmask_ngap.fa
```

I am also queuing up the new assembly (pre pilon).

```bash
bwa index canu/topolish.filledWithCanuAndPBJelly.fasta.gz ; samtools faidx canu/topolish.filledWithCanuAndPBJelly.fasta.gz ; perl ~/perl_toolchain/sequence_data_pipeline/runMergedBamPipeline.pl --fastqs dominette_nextseq_file_list.tab --output canu --reference canu/topolish.filledWithCanuAndPBJelly.fasta.gz --config ./quick_pipeline.cnfg --threads 4
```

OK, the shell script had a few problems. For starters, freebayes can't handle gzipped fastas. Rerunning the last steps of the pipeline.

```bash
# btau4
samtools depth dominette_merged_btau4.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
	2697640645
freebayes -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 2 -F 0.5 -b dominette_merged_btau4.bam -v dominette_merged_btau4.bayes.vcf -f /mnt/iscsi/vnx_gliu_7/reference/bosTau4.fa
perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < dominette_merged_btau4.bayes.vcf
	281999

perl -e '$ns = 281999; $nb = 2697640645; print (-10 * log($ns/$nb)/log(10)); print "\n";'
	39.8073652818702 # Btau4 qv

perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f dominette_merged_btau4_Features.txt -c 1
Entry   Count
COMPR_PE        6407
HIGH_COV_PE     4406
HIGH_NORM_COV_PE        3671
HIGH_OUTIE_PE   988
HIGH_SINGLE_PE  3247
HIGH_SPAN_PE    9240
LOW_COV_PE      135529
LOW_NORM_COV_PE 137377
STRECH_PE       16385

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < dominette_merged_btau4.lumpy.vcf | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        12870
DUPLICATION     1305
INTERCHROM      9031
INVERSION       2152

# Errors per 100 mbp = (25358 / 28.0) = 905.64

# umd3
samtools depth dominette.merged.umd3.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
	2633997017
freebayes -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 2 -F 0.5 -b dominette.merged.umd3.bam -v dominette.merged.umd3.bayes.vcf -f ../../../Genomes/Bos_taurus.UMD3.1.73.fa
perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < dominette.merged.umd3.bayes.vcf
	300091

perl -e '$ns = 300091; $nb = 2633997017; print (-10 * log($ns/$nb)/log(10)); print "\n";'
	39.4336230805122 # UMD3 qv

perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f dominette.merged.umd3_Features.txt -c 1
Entry   Count
COMPR_PE        12348
HIGH_COV_PE     7660
HIGH_NORM_COV_PE        7169
HIGH_OUTIE_PE   2303
HIGH_SINGLE_PE  1295
HIGH_SPAN_PE    4135
LOW_COV_PE      64527
LOW_NORM_COV_PE 67417
STRECH_PE       21891

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < dominette.merged.umd3.lumpy.vcf | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        13963
DUPLICATION     2493
INTERCHROM      8711
INVERSION       5470

# Errors per 100 mbp = (30637 / 28.0) = 1094.18
```

OK, let's summarize things:

| Feature | Btau4 | UMD3 | Description
| :--- | ---: | ---: | :--- |
| QV | 39.80 | 39.43 | Phred-based assessment of INDEL and SNP errors in assembly |
| Errors / 100 Mbp | 905.64 | 1094.18 | Ratio of Lumpy SV calls per 100 Mbp |
| DELETION | 12870 | 13963 | Lumpy-SV deletions |
| DUPLICATION | 1305 | 2493 | Lumpy-SV duplications |
| INTERCHROM | 9031 |  8711 | Lumpy-SV interchromosome regions |
| INVERSION | 2152 |  5470 | Lumpy-SV inversions |
|COMPR_PE         |   6407|12348| Areas with low CE statistics |
|HIGH_COV_PE      |   4406|7660| Higher read coverage |
|HIGH_NORM_COV_PE |   3671|7169| High coverage of normal paired-end reads |
|HIGH_OUTIE_PE    |    988|2303| Regions with high numbers of misoriented or distant pairs |
|HIGH_SINGLE_PE   |   3247|1295| Regions with high numbers of unmapped pairs |
|HIGH_SPAN_PE     |   9240|4135| Regions with high numbers of disc. pairs that map to different scaffolds |
|LOW_COV_PE       | 135529|64527| Low read coverage |
|LOW_NORM_COV_PE  | 137377|67417| Low coverage of normal paired-end reads |
|STRECH_PE        |  16385|21891| Areas with high CE statistics |