# Cattle genome assembly and validation
---
*10/26/2016*

## Table of Contents
* [Sequence alignment and summary statistics](#stats)
* [Polished assembly](#polish)
* [SNP remapping and stats](#snps)

<a name="stats"></a>
## Sequence alignment and summary statistics

I need to align the data to the following cattle assemblies: 

* The UMD3 assembly
* The Btau4 assembly
* The PacBio contigs (the march Cattle assembly)
* The finished assembly (to be generated by Aleksey)

Let's start aligning to the assemblies I have right now. I'm also going to generate the spreadsheet with the information.

> Blade14: /mnt/nfs/nfs2/dbickhart/dominette_asm

```bash
ls /mnt/nfs/nfs2/SequenceData/Dominette/Dominette_NextSeq_data/*/*.fastq.gz | perl -MFile::Basename -e '%data; while(<>){chomp; $orig = $_; $bname = basename($_); @entries = split(/\//, $orig); @bentries = split(/_/, $bname); $data{"$entries[-2]_$bentries[2]"}->{$bentries[3]} = $orig;} foreach my $k (keys(%data)){print $data{$k}->{"R1"} . "\t" . $data{$k}->{"R2"} . "\tdominette\tdominette\n";}' > dominette_nextseq_file_list.tab

# UMD3
perl ~/perl_toolchain/sequence_data_pipeline/runMergedBamPipeline.pl --fastqs dominette_nextseq_file_list.tab --output umd3 --reference ../../Genomes/Bos_taurus.UMD3.1.73.fa --config ./quick_pipeline.cnfg --threads 4

```

Serge's pipeline only works with SGE. I need to hijack some of his commands to run Lumpy and the other tools without using his full pipeline.

```bash
# Preparing discordant and split read bam files
samtools view -b -F 1294 btau4/dominette_merged_btau4.bam > btau4/dominette_merged_btau4.discordants.bam
samtools view -h btau4/dominette_merged_btau4.bam \
          | ~/lumpy-sv/scripts/extractSplitReads_BwaMem -i stdin \
          | samtools view -Sb - \
          > btau4/dominette_merged_btau4.splitters.bam

samtools index btau4/dominette_merged_btau4.discordants.bam
samtools index btau4/dominette_merged_btau4.splitters.bam

# Lumpy analysis
pars=`samtools view btau4/dominette_merged_btau4.bam | head -n100000 | ~/lumpy-sv/scripts/pairend_distro.py -r 150 -X 4 -N 10000 -o btau4/dominette_merged_btau4.histo`
mean=`echo $pars | grep 'mean' | awk '{print $1}' |sed s/mean://g`
sd=`echo $pars |grep 'mean' | awk '{print $NF}' |sed s/stdev://g`
MIN=`echo "$mean $sd" |awk '{printf("%d\n", $1-3*$2)}' |awk '{if ($1 < 0) print 0}'`
MAX=`echo "$mean $sd" |awk '{printf("%d\n", $1+3*$2)}'`

PE=""
SR=""

PE="$PE -pe id:sample,bam_file:btau4/dominette_merged_btau4.discordants.bam,histo_file:btau4/dominette_merged_btau4.histo,mean:$mean,stdev:$sd,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20"
SR="$SR -sr id:sample,bam_file:btau4/dominette_merged_btau4.splitters.bam,back_distance:10,min_mapping_threshold:20,weight:1,min_clip:20"
lumpy -mw 4 -tt 0 $PE $SR > btau4/dominette_merged_btau4.lumpy.vcf

# FRC bam
PE=""
PE="$PE --pe-sam btau4/dominette_merged_btau4.bam --pe-max-insert $MAX"
FRC $PE --genome-size $GS --output btau4/dominette_merged_btau4

# Freebayes
$FREEBAYES -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 1 -F 0.5 -b btau4/dominette_merged_btau4.bam -v btau4/dominette_merged_btau4.bayes.vcf -f $ASM

# QV estimate
NUM_SNP=`cat btau4/dominette_merged_btau4.bayes.vcf |grep -v "#" | awk -F "\t" '{print $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$8}' | tr ';' ' ' | sed s/AB=//g | awk -v WEIGHT=$WEIGHT '{if ($6 > WEIGHT) print $0}' | awk -v SUM=0 '{if (length($4) == length($5)) { SUM+=length($4); } else if (length($4) < length($5)) { SUM+=length($5)-length($4); } else { SUM+=length($4)-length($5)}} END { print SUM}'`

NUM_BP=`samtools depth btau4/dominette_merged_btau4.bam |awk '{if ($NF >= 3) SUM++; } END { print SUM}'`
QV=`echo "$NUM_SNP $NUM_BP" | awk '{print (-10*log($1/$2)/log(10))}'`
echo $QV > btau4/dominette_merged_btau4.qv
```

I consolidated the above code into a shell script that can run on each merged bam file in sequence.

```bash
sh serge_script_oneshot.sh btau4/dominette_merged_btau4 /mnt/iscsi/vnx_gliu_7/reference/bosTau4.fa.gz

sh serge_script_oneshot.sh umd3/dominette.merged.umd3 /mnt/iscsi/vnx_gliu_7/reference/umd3_kary_unmask_ngap.fa

sh serge_script_oneshot.sh canu/canu.dominette.topolish canu/topolish.filledWithCanuAndPBJelly.fasta
```

I am also queuing up the new assembly (pre pilon).

```bash
bwa index canu/topolish.filledWithCanuAndPBJelly.fasta.gz ; samtools faidx canu/topolish.filledWithCanuAndPBJelly.fasta.gz ; perl ~/perl_toolchain/sequence_data_pipeline/runMergedBamPipeline.pl --fastqs dominette_nextseq_file_list.tab --output canu --reference canu/topolish.filledWithCanuAndPBJelly.fasta.gz --config ./quick_pipeline.cnfg --threads 4
```

OK, the shell script had a few problems. For starters, freebayes can't handle gzipped fastas. Rerunning the last steps of the pipeline.

```bash
# btau4
samtools depth dominette_merged_btau4.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
	2697640645
freebayes -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 2 -F 0.5 -b dominette_merged_btau4.bam -v dominette_merged_btau4.bayes.vcf -f /mnt/iscsi/vnx_gliu_7/reference/bosTau4.fa
perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < dominette_merged_btau4.bayes.vcf
	281999

perl -e '$ns = 281999; $nb = 2697640645; print (-10 * log($ns/$nb)/log(10)); print "\n";'
	39.8073652818702 # Btau4 qv

perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f dominette_merged_btau4_Features.txt -c 1
Entry   Count
COMPR_PE        6407
HIGH_COV_PE     4406
HIGH_NORM_COV_PE        3671
HIGH_OUTIE_PE   988
HIGH_SINGLE_PE  3247
HIGH_SPAN_PE    9240
LOW_COV_PE      135529
LOW_NORM_COV_PE 137377
STRECH_PE       16385

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < dominette_merged_btau4.lumpy.vcf | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        12870
DUPLICATION     1305
INTERCHROM      9031
INVERSION       2152

# Errors per 100 mbp = (25358 / 28.0) = 905.64

# umd3
samtools depth dominette.merged.umd3.bam | perl -e '$c = 0; while(<>){chomp; @s = split(/\t/); if($s[2] >= 3){$c++;}} print "$c\n";'
	2633997017
freebayes -C 2 -0 -O -q 20 -z 0.02 -E 0 -X -u -p 2 -F 0.5 -b dominette.merged.umd3.bam -v dominette.merged.umd3.bayes.vcf -f ../../../Genomes/Bos_taurus.UMD3.1.73.fa
perl -e '$c = 0; while(<>){chomp; @F = split(/\t/); if($F[0] =~ /^#/){next;} ($ab) = $F[7] =~ /AB=(.{1,10})\;ABP/; if($ab < 0.65){next;}else{ $la = length($F[3]); $lb = length($F[4]); if($la == $lb){$c++;}elsif($la < $lb){$c += $lb - $la;}else{$c += $la - $lb;}}} print "$c\n";' < dominette.merged.umd3.bayes.vcf
	300091

perl -e '$ns = 300091; $nb = 2633997017; print (-10 * log($ns/$nb)/log(10)); print "\n";'
	39.4336230805122 # UMD3 qv

perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f dominette.merged.umd3_Features.txt -c 1
Entry   Count
COMPR_PE        12348
HIGH_COV_PE     7660
HIGH_NORM_COV_PE        7169
HIGH_OUTIE_PE   2303
HIGH_SINGLE_PE  1295
HIGH_SPAN_PE    4135
LOW_COV_PE      64527
LOW_NORM_COV_PE 67417
STRECH_PE       21891

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < dominette.merged.umd3.lumpy.vcf | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        13963
DUPLICATION     2493
INTERCHROM      8711
INVERSION       5470

# Errors per 100 mbp = (30637 / 28.0) = 1094.18


## Computomix
perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f canu/canu.dominette.topolish_Features.txt -c 1
Entry   Count
COMPR_PE        6526
HIGH_COV_PE     7333
HIGH_NORM_COV_PE        5759
HIGH_OUTIE_PE   80
HIGH_SINGLE_PE  118
HIGH_SPAN_PE    5982
LOW_COV_PE      52772
LOW_NORM_COV_PE 50719
STRECH_PE       16752

lumpy -mw 4 -tt 0 -pe id:sample,bam_file:canu.dominette.topolish.discordants.bam,histo_file:canu.dominette.topolish.histo,mean:628.478,stdev:168.47,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 -sr id:sample,bam_file:canu.dominette.topolish.splitters.bam,back_distance:10,min_mapping_threshold:20,weight:1,min_clip:20 > canu.dominette.topolish.lumpy.vcf

perl -lane '$F[10] =~ s/TYPE://g; print "$F[10]";' < canu/canu.dominette.topolish.lumpy.vcf  | perl ~/perl_toolchain/bed_cnv_fig_table_pipeline/tabFileColumnCounter.pl -f stdin -c 0
Entry   Count
DELETION        4272
DUPLICATION     320
INTERCHROM      2132
INVERSION       487


```

OK, let's summarize things:

| Feature | Btau4 | UMD3 | Computomix | Aleksey |Description |
| :--- | ---: | ---: | ---: | ---: |:--- |
| QV | 39.80 | 39.43 | | | Phred-based assessment of INDEL and SNP errors in assembly |
| Errors / 100 Mbp | 905.64 | 1094.18 | | | Ratio of Lumpy SV calls per 100 Mbp |
| DELETION | 12870 | 13963 |  | | Lumpy-SV deletions |
| DUPLICATION | 1305 | 2493 | | | Lumpy-SV duplications |
| INTERCHROM | 9031 |  8711 | | | Lumpy-SV interchromosome regions |
| INVERSION | 2152 |  5470 |  | | Lumpy-SV inversions |
|COMPR_PE         |   6407|12348| 6526| 9000 | Areas with low CE statistics |
|HIGH_COV_PE      |   4406|7660| 7333| 10098 | Higher read coverage |
|HIGH_NORM_COV_PE |   3671|7169| 5759 | 7944 | High coverage of normal paired-end reads |
|HIGH_OUTIE_PE    |    988|2303| 80| 79 | Regions with high numbers of misoriented or distant pairs |
|HIGH_SINGLE_PE   |   3247|1295| 118 | 251 |Regions with high numbers of unmapped pairs |
|HIGH_SPAN_PE     |   9240|4135| 5982 | 14180 |Regions with high numbers of disc. pairs that map to different scaffolds |
|LOW_COV_PE       | 135529|64527| 52772 | 100814 |Low read coverage |
|LOW_NORM_COV_PE  | 137377|67417| 50719 | 105271 |Low coverage of normal paired-end reads |
|STRECH_PE        |  16385|21891| 16752 | 15079 |Areas with high CE statistics |

<a name="polished"></a>
## Polished assembly

Now that we have the polished assembly back from Aleksey, it's time to process it.

```bash
module load bwa
module load samtools/1.3-20-gd49c73b

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="bwa index polished.fa"
sbatch --mem=2000 --nodes=1 --ntasks-per-node=1 --wrap="samtools faidx polished.fa"

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="java -Xmx19g -jar /mnt/nfs/nfs2/bickhart-users/binaries/GetMaskBedFasta/store/GetMaskBedFasta.jar -f polished.fa -o polished.gaps.bed -s polished.gaps.stats"
sbatch --nodes=1 --mem=2000 --ntasks-per-node=8 --wrap 'samtools merge -c -p --threads 8 polished.merged.dominette.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L001_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L002_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L003_001.bam polishedAsm.NextSeq.dominette.dominette.LIB18483_S1_L004_001.bam'

sbatch --nodes=1 --ntasks-per-node=1 --mem=1000 --wrap='samtools index bwa-out/polished.merged.dominette.bam'
sbatch serge_script_oneshot.sh polished/bwa-out/polished.merged.dominette polished/polished.fa

# Lumpy failed because of weird scripting errors. Rerunning...
sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; samtools view polished.merged.dominette.bam | tail -n+100000 | /opt/agil_cluster/lumpy-sv-0.2.12-51-g16b6876/bin/../scripts/pairend_distro.py -r 150 -X 4 -N 10000 -o polished.merged.dominette.histo"

sbatch --mem=20000 --nodes=1 --ntasks-per-node=5 --wrap="module load lumpy-sv/0.2.12-51-g16b6876; lumpy -mw 4 -tt 0 -pe id:dominette,bam_file:polished.merged.dominette.bam,histo_file:polished.merged.dominette.histo,mean:626.926292629,stdev:193.453829908,read_length:150,min_non_overlap:150,discordant_z:5,back_distance:10,weight:1,min_mapping_threshold:20 > polished.merged.dominette.lumpy.vcf"
```

<a name="ctx"></a>
## Computomix assembly

The polished assembly looks corrupted... I'm going to run a comparison with the real computomix assembly to see how that panned out.

> fry: /mnt/nfs/nfs2/dbickhart/dominette_asm/ctx

```bash
sh create_bwa_batchfiles.sh dominette_nextseq_file_list.tab
sbatch --nodes=1 --ntasks-per-node=2 --mem=10000 --wrap="module load bwa; module load samtools; bwa index CTX3.fasta; samtools faidx CTX3.fasta"

sleep 3h; find batchfiles-bwa/ -name *.sh | xargs -I {} sbatch {}

```

<a name="snps"></a>
## SNP remapping and stats

These are my notes on the remapping of SNP probes from the HD array to the new assembly. I have two main goals here:

* Generate a SNP location list for Paul and John to check
* Determine how many SNP locations have moved from UMD3

> 3850: /home/bickhart
```bash
perl -e 'for($x = 0; $x < 6; $x++){<>;} while(<>){chomp; if($_ =~ /^#/){next;} @s = split(/,/); @b = split(/[\[\]]/, $s[6]); $b[2] =~ tr/ACGT/TGCA/; $b[2] = reverse($b[2]); print ">$s[1].f\n$b[0]\n>$s[1].r\n$b[2]\n";} close IN;' < /work1/grw/chips/GH2/GGP_HDv2_B_StrandReport_FDT_V1.csv > ggp_probe_design.fa

perl -e 'open(O1, "> ggp_probe_design.1.fa"); open(O2, "> ggp_probe_design.2.fa"); while($n1 = <>){ $s1 = <>; $n2 = <>; $s2 = <>; $n1 =~ s/.f//; $n2 =~ s/.r//; print O1 "$n1$s1"; print O2 "$n2$s2"; }' < ggp_probe_design.fa
```

> pwd: /home/dbickhart/share/btau4_data

```bash
# I converted the BovineHD data into single line fasta entries.
```



